{"pages":[],"posts":[{"title":"JVM内存管理","permalink":"https://binchencoder.github.io/2019/09/11/JVM内存管理/","text":"JVM内存管理作为三大工业级别语言之一的JAVA如此受企业青睐有加，离不开她背后JVM的默默复出。只是由于JAVA过于成功以至于我们常常忘了JVM平台上还运行着像Clojure/Groovy/Kotlin/Scala/JRuby/Jython这样的语言。我们享受着JVM带来跨平台“一次编译到处执行”的便利和自动内存回收的安逸。 JVM是JAVA的核心基础，也是掌握JAVA语言的重难点，如果没有理解JVM的知识体系，就不要说自己是JAVA高手。最近我打算换工作，所以来重新回顾JVM的相关知识，为面试准备。JVM体系内知识点很多，通过以下关键词来简单概括下： 类结构，类加载器，加载，链接，初始化，双亲委派，热部署，隔离，堆，栈，方法区，计数器，内存回收，执行引擎，调优工具，JVMTI，JDWP，JDI，热替换，字节码，ASM，CGLIB，DCEVM 本文从JVM的内存结构入手，介绍JVM逻辑内存的分布和管理方式，同时列举常用的JVM调优工具和使用方法。 内存结构逻辑分区JVM内存从应用逻辑上可分为如下区域： 程序计数器程序计数器是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器，每个线程都需要一个程序计数器。在虚拟机的概念模型里（仅仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时，就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳准、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 简单理解就是程序计数器保证了程序的正常执行。 虚拟机栈方法执行时创建栈帧(存储局部变量，操作栈，动态链接，方法出口)编译时期就能确定占用空间大小，线程请求的栈深度超过jvm运行深度时抛StackOverflowError，当jvm栈无法申请到空闲内存时抛OutOfMemoryError，通过-Xss,-Xsx来配置初始内存 本地方法栈执行本地方法，如操作系统native接口 堆存放对象的空间，通过-Xmx,-Xms配置堆大小，当堆无法申请到内存时抛OutOfMemoryError 方法区存储类数据，常量，常量池，静态变量，通过MaxPermSize参数配置 对象访问初始化一个对象，其引用存放于栈帧，对象存放于堆内存，对象包含属性信息和该对象父类、接口等类型数据（该类型数据存储在方法区空间，对象拥有类型数据的地址） 内存模型堆内存堆内存是运行时的数据区，从中分配所有的Java类实例和数组的内存，可以理解为目标应用依赖的对象。堆在JVM启动时创建，并在应用程序运行时可能会增大或减小。可以使用-Xms`选项指定堆的大小。堆可以是固定大小或可变大小，具体取决于垃圾收集策略。可以使用-Xmx选项设置最大堆大小。默认情况下，最大堆大小设置为64M。 JVM堆内存在物理上分为两部分：新生代和老年代。新生代是为分配新对象而保留堆空间。当新生代占用完时，Minor GC垃圾收集器会对新生代区域执行垃圾回收动作。其中在新生代中生活了足够长的所有对象被迁移到老生代，从而释放新生代空间以进行更多的对象分配。此垃圾收集称为Minor GC。新生代分分为三个子区域：伊甸园Eden区和两个幸存区S0`和`S1。 关于新生代空间： 大多数新创建的对象都位于Eden区内存空间 当Eden区填满对象时，执行Minor GC并将所有幸存对象移动到其中一个幸存区空间 Minor GC还会检查幸存区对象并将其移动到其他幸存者空间，也即是幸存区总有一个是空的 在多次GC后还存活的对象被移动到老年代内存空间。至于经过多少次GC晋升老年代则由参数配置，通常为15 当老年区填满时，老年区同样会执行垃圾回收。老年区还包含那些经过多Minor GC后还存活的长寿对象。垃圾收集器在老年代内存中执行的垃圾回收称为Major GC，通常需要更长的时间。 Full GC ？？？ 非堆内存JVM堆以外的内存称为非堆内存。也即是JVM自身预留的内存区域，包含JVM缓存空间，类结构如常量池、字段和方法数据，方法，构造方法。类非堆内存的默认最大大小为64MB。可以用 -XX: MaxPermSize VM选项更改此选项，非堆内存通常包含如下性质的区域空间： 元空间（Metaspace） 在Java 8以上版本已经没有Perm Gen这块区域了，这也意味着不会再由关于“java.lang.OutOfMemoryError：PermGen”内存问题存在了。与驻留在Java堆中的Perm Gen不同，Metaspace不是堆的一部分。类元数据多数情况下都是从本地内存中分配的。默认情况下，元空间会自动增加其大小(直接又底层操作系统提供)，而Perm Gen始终具有固定的上限。可以使用两个新标志来设置Metaspace的大小，它们是：“ - XX：MetaspaceSize ”和“ -XX：MaxMetaspaceSize ”。Metaspace背后的含义是类的生命周期及其元数据与类加载器的生命周期相匹配。也就是说，只要类加载器处于活动状态，元数据就会在元数据空间中保持活动状态，并且无法释放。 代码缓存 运行Java程序时，它以分层方式执行代码。在第一层，它使用客户端编译器（C1编译器）来编译代码。分析数据用于服务器编译的第二层（C2编译器），以优化的方式编译该代码。默认情况下，Java 7中未启用分层编译，但在Java 8中启用了分层编译。实时（JIT）编译器将编译的代码存储在称为代码缓存的区域中。它是一个保存已编译代码的特殊堆。如果该区域的大小超过阈值，则该区域将被刷新，并且GC不会重新定位这些对象。Java 8中已经解决了一些性能问题和编译器未重新启用的问题，并且在Java 7中避免这些问题的解决方案之一是将代码缓存的大小增加到一个永远不会达到的程度。 方法区 方法区域是Perm Gen中空间的一部分，用于存储类结构（运行时常量和静态变量）以及方法和构造函数的代码。 内存池 内存池由JVM内存管理器创建，用于创建不可变对象池。内存池可以属于Heap或Perm Gen，具体取决于JVM内存管理器实现。 常量池 常量包含类运行时常量和静态方法，常量池是方法区域的一部分。 Java堆栈内存 Java堆栈内存用于执行线程。它们包含特定于方法的特定值，以及对从该方法引用的堆中其他对象的引用。 Java堆内存配置项 Java提供了许多内存配置项，我们可以使用它们来设置内存大小及其比例，常用的如下： VM Switch 描述 -Xms 用于在JVM启动时设置初始堆大小 -Xmx 用于设置最大堆大小 -Xmn 设置新生区的大小，剩下的空间用于老年区 -XX：PermGen 用于设置永久区存初始大小 -XX：MaxPermGen 用于设置Perm Gen的最大尺寸 -XX：SurvivorRatio 提供Eden区域的比例 -XX：NewRatio 用于提供老年代/新生代大小的比例，默认值为2 内存回收垃圾回收策略流程策略算法References: https://mp.weixin.qq.com/s/3_DEPdZTnGmdGBd5iTrVjQ https://www.cnblogs.com/manayi/p/9290490.html"},{"title":"Mac平台搭建Golang环境","permalink":"https://binchencoder.github.io/2019/08/08/Mac平台搭建Golang环境/","text":"Overview我大概是在两年前开始接触Golang语言，当时我们公司在北美成立研发中心，核心成员都是来自Google、微软等世界一流互联网公司。那时起我们才真正有了CTO这个职位。他来自Google，所以把Google的核心开发语言Golang带到我们公司并大力推广。要求全员学习Golang。 当时业务部门的同事都比较抵触学习Golang，包括我在内。大家都把Java语言当作了吃饭的饭碗，认为Golang是一门比较难的语言，不情愿在这个上面花时间。后来事实证明当初的想法是错误的，其实Golang入门还是很容易的，包括搭建环境，相比较Java而言，要容易的多。 听我啰嗦了这么多，大家可不要认为Golang就是万能的。任何一门语言都有其优点和缺点，Golang也不例外。 优点 Golang语法简单，可读性非常高，入门容易 基于 goroutines 和 channels 的简单并发编程 丰富的标准库 Golang性能优越 语言层面定义源代码的格式化 标准化的测试框架 Golang程序编译快，方便操作 Defer声明，避免忘记清理 方法多返回值：定义function可以返回多个值 缺点 Golang忽略了现代语言的进步 接口是结构类型 没有枚举 := / var 两难选择 说了这么多，让我们开始动手吧，本篇内容只会介绍如何搭建Golang开发环境 Mac搭建Golang开发环境介绍两种方式安装Golang环境 通过HomeBrew安装Homebrew有点类似于Linux操作系统中的apt-get（Ubuntu）、yum（yum），Mac的操作系统中使用它解决包依赖问题，套用官方的话来说：使用 Homebrew 安装 Apple 没有预装但 你需要的东西。 安装homebrew，已有则跳过1fabric:~ fabric$ ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装成功则提示 12345678910==&gt; Installation successful!==&gt; Homebrew has enabled anonymous aggregate user behaviour analytics.Read the analytics documentation (and how to opt-out) here: https://docs.brew.sh/Analytics.html==&gt; Next steps:- Run `brew help` to get started- Further documentation: https://docs.brew.sh 安装Golang 首先看看有哪些Golang版本可用 123456789101112131415chenbindeMacBook-Pro:BazelWorkspace chenbin$ brew search go==&gt; Formulaealgol68g gnu-go gocr google-authenticator-libpam gosu lgogdownloader percona-server-mongodbanycable-go go gocryptfs google-benchmark gotags libgosu protoc-gen-goarangodb go-bindata godep google-java-format goto mongo-c-driver pygobjectargon2 go-jira goenv google-sparsehash gource mongo-cxx-driver pygobject3aws-google-auth go-statik gofabric8 google-sql-tool govendor mongo-orchestration ringojsbogofilter go@1.10 goffice googler gowsdl mongodb spaceinvaders-gocargo-completion go@1.11 golang-migrate goolabs gox mongodb@3.0 spigotcertigo go@1.9 gollum goose gst-plugins-good mongodb@3.2 svgocgoban goaccess golo gopass gx-go mongodb@3.4 wegoclingo goad gom gor hugo mongodb@3.6 wireguard-godjango-completion gobby gomplate goreleaser jfrog-cli-go mongoose write-goodforego gobject-introspection goocanvas goreman jpegoptim pangofuego gobuster goofys gost lego pangomm 我们发现最新的有1.11可以使用 安装brew下最新版本的Golang 1fabric:~ fabric$ brew install go@1.11 配置Golang的环境变量 1chenbindeMacBook-Pro:BazelWorkspace chenbin$ vi /Users/chenbin/.bash_profile NOTE: 在Linux环境下是 vim ~/.bashrc 1234export GOROOT=/usr/local/goexport GOPATH=/Volumes/BazelWorkspace/bazel-goexport PATH=$GOROOT/bin:$GOPATH/bin:$PATH NOTE: GOPATH可以根据个人习惯设置为其他目录 让改动生效 1chenbindeMacBook-Pro:BazelWorkspace chenbin$ source ~/.bash_profile 试一试Golang是否安装成功 出现以下内容，则安装成功 123456789101112131415161718192021222324252627chenbindeMacBook-Pro:BazelWorkspace chenbin$ go envGOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOCACHE=&quot;/Users/chenbin/Library/Caches/go-build&quot;GOEXE=&quot;&quot;GOFLAGS=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;/Volumes/BazelWorkspace/bazel-go&quot;GOPROXY=&quot;&quot;GORACE=&quot;&quot;GOROOT=&quot;/usr/local/go&quot;GOTMPDIR=&quot;&quot;GOTOOLDIR=&quot;/usr/local/go/pkg/tool/darwin_amd64&quot;GCCGO=&quot;gccgo&quot;CC=&quot;clang&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot;GOMOD=&quot;&quot;CGO_CFLAGS=&quot;-g -O2&quot;CGO_CPPFLAGS=&quot;&quot;CGO_CXXFLAGS=&quot;-g -O2&quot;CGO_FFLAGS=&quot;-g -O2&quot;CGO_LDFLAGS=&quot;-g -O2&quot;PKG_CONFIG=&quot;pkg-config&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/hw/12mwhf310xd8m8k3bhtjxqp00000gn/T/go-build698784611=/tmp/go-build -gno-record-gcc-switches -fno-common&quot; 直接下载Golang包 直接在github下载源程序包 根据自己的需求下载适当的版本，推荐选择当下最新版本 下载地址： https://github.com/golang/go/releases 解压到你想配置的GOROOT目录 配置Golang环境变量（与通过Homebrew安装Golang的配置方式一样) END我个人推荐通过直接下载源程序包的方式安装，不仅省去了安装Homebrew的步骤，而且耗时更短。 我们开发golang的code一般放在 $GOPATH/src 目录下，下一章我会教大家如何利用工具简单而且方便的开发Golang NOTE: 提前剧透一下，大家可以先看看 https://github.com/linuxerwang/gobazel"},{"title":"Linux文件常用命令","permalink":"https://binchencoder.github.io/2019/08/02/Linux 文件常用命令/","text":"Linux文件常用命令文件解压缩 解压 .tar.gz 和 .tgz1tar zxvf filename.tar.gz 压缩 .tar.gz 和 .tgz1tar zcvf filename.tar.gz linux下tar命令解压到指定的目录：1#tar xvf /bbs.tar.zip -C /zzz/bbs 把根目录下的bbs.tar.zip解压到/zzz/bbs下，前提要保证存在/zzz/bbs这个目录这个和cp命令有点不同，cp命令如果不存在这个目录就会自动创建这个目录！附：用tar命令打包例：将当前目录下的zzz文件打包到根目录下并命名为zzz.tar.gz 12&gt; #tar zcvf /zzz.tar.gz ./zzz&gt; 解压 .zip1unzip filename.zip 压缩 .zip12zip filename.zip压缩一个目录使用 -r 参数， -r 递归。 例： $ zip -r filename.zip dirname 解压 .rar1rar x filename.rar 压缩 .rar1rar a filename.rar dirname 文件搜索最强大的搜索命令：findfind命令是我们在Linux系统中用来进行文件搜索用的最多的命令，功能特别强大。但是我们要说的是尽量少用find命令去执行搜索任务，就算要搜索我们也应该尽量的缩小范围，也不要在服务器使用高峰期进行文件搜索，因为搜索也是很占系统资源的。这就需要我们在进行Linux文件整理的时候，尽量规范化，什么文件放在什么目录下都要有比较好的约定。 根据文件或目录名称搜索 find 【搜索目录】【-name或者-iname】【搜索字符】：-name和-iname的区别一个区分大小写，一个不区分大小写 1234find /etc -name init (精准搜索，名字必须为 init 才能搜索的到)find /etc -iname init (精准搜索，名字必须为 init或者有字母大写也能搜索的到)find /etc -name *init (模糊搜索，以 init 结尾的文件或目录名) find /etc -name init??? (模糊搜索，？ 表示单个字符，即搜索到 init___) 根据 文件大小 搜索比如：在根目录下查找大于 100M 的文件 1find / -size +204800 NOTE: 这里 +n 表示大于，-n 表示小于，n 表示等于1 数据块 == 512 字节 ==0.5KB，也就是1KB等于2数据块100MB == 102400KB==204800数据块 递归搜索并删除123find /tmp/98/upload -name *.avi -type f -print -exec rm -rf &#123;&#125; \\;find . -name abc -type d -print -exec rm -rf &#123;&#125; \\; “.” 表示从当前目录开始递归查找 “ -name ‘*.exe’ “根据名称来查找，要查找所有以.exe结尾的文件夹或者文件 “ -type f “查找的类型为文件 “-print” 输出查找的文件目录名 最主要的是是-exec了，-exec选项后边跟着一个所要执行的命令，表示将find出来的文件或目录执行该命令。exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{}，一个空格和一个\\，最后是一个分号"},{"title":"Spring Boot中application.properties与bootstrap.properties的区别","permalink":"https://binchencoder.github.io/2019/08/01/Spring Boot中application.properties与bootstrap.properties的区别/","text":"application.propertes (application.yml)现在使用SpringBoot是Java世界里的主流选择，它大大简化了应用初始搭建以及开发过程，该框架使用了特定的方式来进行配置，从而是开发人员不在需要定义样板化的配置。今天就带大家来了解下application.properties 使用application.properties，一般情况下主要用来配置服务中一些最基本的属性，如 数据库连接、日志相关配置。其他的用法还有 一般属性使用、自定义属性使用、属性间的引用(占位符)、随机数的使用、数据类型自动转换、嵌套属性注入 如：123456789101112spring.profiles.active=dev,vexillary-service,skylb,file_server,kafka_monitor_0.8,metrics#gRPCgrpc.port=6567#metricsmetrics.scrapePort=10000# logging levellogging.level.root=errorlogging.level.com.jingoal.grpc=debuglogging.level.com.jingoal.approval=debug application.properties与bootstrap.properties的区别两者主要区别是加载顺序不同，bootstrap.properties在application.properties 之前加载，bootstrap.properties用于应用程序上下文的引导阶段 典型场景 当时用Spring Cloud Config Server的时候，你应该在bootstraop.properties里面指定spring.application.name 和 spring.cloud.config.server.git.uri 一些加密/解密的信息 技术上, bootstrap.properties由父Spring ApplicationContext加载。父ApplicationContext 被加载到使用application.properties的之前。 当使用SpringCloud的时候，配置信息一般是从config server加载的，为了取得配置信息（比如密码等），你需要一些提早的或引导配置。因此，把config server信息放在bootstrap.properties，用来加载真正需要的配置信息。 属性覆盖问题启动上下文时，Spring Cloud会创建一个BootStrap Context，作为Spring应用的Application Context的父上下文。初始化的时候，Bootstrap Context负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment。 Bootstrap属性有高优先级，默认情况下，他们不会被本地配置覆盖。Bootstrap Context和Application Context有着不同的约定，所以新增了一个bootstrap.properties，而不是使用application.properties。保证Bootstrap Context和Application Context配置的分离。"},{"title":"MySQL优化原理","permalink":"https://binchencoder.github.io/2019/07/29/MySQL优化原理/","text":"前言说起MySQL的查询优化，相信大家收藏了一堆奇技淫巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。 MySQL逻辑架构如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。 MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。 MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。 最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。 MySQL查询过程我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。 当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？ 客户端/服务端通信协议MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。 客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。 与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。 查询缓存在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。 MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。 既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外： 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗 基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如： 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存 最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。"},{"title":"Linux查看系统硬件信息","permalink":"https://binchencoder.github.io/2019/07/29/Linux查看系统硬件信息/","text":"Linux查看系统硬件信息查看当前操作系统内核信息12chenbin@chenbin-ThinkPad:~$ uname -aLinux chenbin-ThinkPad 4.15.0-36-generic #39-Ubuntu SMP Mon Sep 24 16:19:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 查看当前操作系统发行版信息12chenbin@chenbin-ThinkPad:~$ cat /etc/issueUbuntu 18.04.1 LTS \\n \\l CPUCPU详细信息1234567891011121314151617181920212223242526ubuntu@mini-11:~$ lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bit #CPU 运行模式Byte Order: Little Endian #字节序CPU(s): 4 #CPU个数On-line CPU(s) list: 0-3 #在线 CPU 列表Thread(s) per core: 2 #每个核的线程数Core(s) per socket: 2 #每个cpu插槽核数/每颗物理cpu核数Socket(s): 1 #CPU插槽数NUMA node(s): 1 #NUMA 节点Vendor ID: GenuineIntel #厂商 IDCPU family: 6 #CPU系列Model: 69 #型号Model name: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHzStepping: 1CPU MHz: 2290.247 #CPU MHzCPU max MHz: 3300.0000 #CPU 最大 MHzCPU min MHz: 800.0000 #CPU 最小 MHzBogoMIPS: 5387.11Virtualization: VT-xL1d cache: 32K #一级缓存32K（google了下，这具体表示表示cpu的L1数据缓存为32k）L1i cache: 32K #一级缓存32K（具体为L1指令缓存为32K）L2 cache: 256K #二级缓存256KL3 cache: 4096K #三级缓存4096KNUMA node0 CPU(s): 0-3Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts NOTE: 查看12### 查看物理CPU个数 [root@DB-Server ~]# cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l [root@DB-Server ~]# dmesg | grep CPU | grep “Physical Processor ID” | uniq | wc -l12### 查看逻辑CPU个数 [root@DB-Server ~]# cat /proc/cpuinfo | grep “processor” | wc -l [root@DB-Server ~]# dmesg | grep “CPU” | grep “processor” | wc -l12### 查看CPU是几核的 [root@DB-Server ~]# cat /proc/cpuinfo | grep “cores” | uniq cpu cores : 312### 查看CPU的主频 [root@DB-Server ~]# cat /proc/cpuinfo | grep MHz | uniqcpu MHz : 800.000 [root@DB-Server ~]# cat /proc/cpuinfo | grep MHzcpu MHz : 800.000cpu MHz : 800.000cpu MHz : 800.00012### 查看CPU型号信息 [root@DB-Server ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 3 AMD Athlon(tm) II X3 450 Processor12### 通过physical id 可以判断物理CPU个数 [root@DB-Server ~]# cat /proc/cpuinfo | grep physical | uniq -cphysical id : 0address sizes : 48 bits physical, 48 bits virtualphysical id : 0address sizes : 48 bits physical, 48 bits virtualphysical id : 0address sizes : 48 bits physical, 48 bits virtual12### 查看CPU是否支持64位运算 [root@DB-Server ~]# cat /proc/cpuinfo | grep flags | grep ‘lm’ | wc -l3 结果大于0，说明支持64位运算，lm指long mode 支持lm则是64bit12345```[root@DB-Server ~]# getconf LONG_BITetl:/home/etl/$getconf LONG_BIT（另外一台服务器）说明当前CPU运行在32位模式下，当不代表CPU不支持64位 查看内存信息1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@DB-Server ~]# more /proc/meminfoMemTotal: 7541288 kBMemFree: 215388 kBBuffers: 186228 kBCached: 6433572 kBSwapCached: 77404 kBActive: 5489928 kBInactive: 1346252 kBActive(anon): 5193596 kBInactive(anon): 1015024 kBActive(file): 296332 kBInactive(file): 331228 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 9781240 kBSwapFree: 9430432 kBDirty: 0 kBWriteback: 0 kBAnonPages: 139432 kBMapped: 3878064 kBShmem: 5992240 kBSlab: 328284 kBSReclaimable: 159572 kBSUnreclaim: 168712 kBKernelStack: 2056 kBPageTables: 99256 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 13551884 kBCommitted_AS: 6943792 kBVmallocTotal: 34359738367 kBVmallocUsed: 301620 kBVmallocChunk: 34359431420 kBHardwareCorrupted: 0 kBAnonHugePages: 30720 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 8128 kBDirectMap2M: 2611200 kBDirectMap1G: 5242880 kB"},{"title":"RPC框架","permalink":"https://binchencoder.github.io/2019/07/21/RPC框架/","text":"前言大概是三年前我开始接触RPC，那时作为一个刚入职场三年的新兵，在公司技术架构决策层上还没有什么发言权。一直沿用前辈搭建的技术架构来开发应用系统，当时还没有前后端分离，采用的框架是Spring MVC + JSP，每个应用服务都是一个war，服务间的调用是通过共享访问数据库的代码包(jar)来实现，现在想想那时的技术是真的Low，导致现在欠了很多的技术债，直到现在我们也还在努力的还债。 后来随着服务不断增加，而且服务之前还需要互相调用，这种方式导致维护的成本越来越高。这时领导才下定决心要重构技术架构，要引入微服务并进行前后端分离，这才拉开了服务化的进程，从那时起我们开始引入RPC框架。 本片文章我会带领大家来了解这几个方面的内容：什么是RPC，为什么要使用RPC以及常见的RPC框架。 RPC简介RPC 是远程过程调用（Remote Procedure Call）的缩写形式，Birrell 和 Nelson 在 1984 发表于 ACM Transactions on Computer Systems 的论文《Implementing remote procedure calls》对 RPC 做了经典的诠释。RPC 是指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。而这一过程，对于开发人员来说是透明的。上图描述了数据报在一个简单的RPC传递的过程 当两个物理分离的子系统需要建立逻辑上的关联时，RPC 是牵线搭桥的常见技术手段之一。除 RPC 之外，常见的多系统数据交互方案还有分布式消息队列、HTTP 请求调用、数据库和分布式缓存等。 其中 RPC 和 HTTP 调用是没有经过中间件的，它们是端到端系统的直接数据交互。HTTP 调用其实也可以看成是一种特殊的 RPC，只不过传统意义上的 RPC 是指长连接数据交互，而 HTTP 一般是指即用即走的短链接。 RPC 在我们熟知的各种中间件中都有它的身影。Nginx/Redis/MySQL/Dubbo/Hadoop/Spark/Tensorflow 等重量级开源产品都是在 RPC 技术的基础上构建出来的，我们这里说的 RPC 指的是广义的 RPC，也就是分布式系统的通信技术。RPC 在技术中的地位好比我们身边的空气，它无处不在，但是又有很多人根本不知道它的存在。 为什么要使用RPC 首先要明确一点：RPC可以用HTTP协议实现，并且用HTTP是建立在TCP之上最广泛使用的RPC，但是互联网公司往往用自己的私有协议，比如鹅厂的JCE协议，私有协议不具备通用性为什么还要用呢？因为相比于HTTP协议，RPC采用二进制字节码传输，更加高效也更加安全。 现在业界提倡“微服务”的概念，而服务之间通信目前有两种方式，RPC就是其中一种。RPC可以保证不同服务之间的互相调用。即使是跨语言跨平台也不是问题，让构建分布式系统更加容易。 RPC框架都会有服务降级，流程控制的功能，保证服务的高可用。 RPC框架要想了解一个RPC框架是如何实现的，首先要明白以下几点： Call ID映射 我们怎么告诉远程机器我们要调用Multiply，而不是Add或者FooBar呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 序列化和反序列化 客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 网络传输 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西 常用的RPC框架常用的RPC框架在语言上支持Java的最多，golang次之 Netty - Netty框架不局限于RPC，更多的是作为一种网络协议的实现框架，比如HTTP，由于RPC需要高效的网络通信，就可能选择以Netty作为基础。 brpc是一个基于protobuf接口的RPC框架，在百度内部称为“baidu-rpc”，它囊括了百度内部所有RPC协议，并支持多种第三方协议，从目前的性能测试数据来看，brpc的性能领跑于其他同类RPC产品。 Dubbo是Alibaba开发的一个RPC框架，远程接口基于Java Interface, 依托于Spring框架。 gRPC的Java实现的底层网络库是基于Netty开发而来，其Go实现是基于net库。 Thrift是Apache的一个项目(http://thrift.apache.org)，前身是Facebook开发的一个RPC框架，采用thrift作为IDL (Interface description language)。 jsonrpc END后面我会继续发文深入介绍gRPC框架和在工作中是如何应用gRPC框架的"},{"title":"MySQL中 乐观锁、悲观锁、共享锁、排它锁、行锁、表锁的理解","permalink":"https://binchencoder.github.io/2019/01/20/MySQL锁的理解/","text":"前言MySQL/InnoDB的加锁，一直是一个面试中常见的话题。例如，数据库如果有高并发请求，如果保证数据完整性？产生死锁问题如何排查并解决？我在工作过程中，也会经常用到，乐观锁，排它锁 等。最近针对这几个概念进行学习，记录一下。 注: MySQL是一个支持插件式存储引擎的数据库系统。本文下面的所有介绍，都是基于InnoDB存储引擎，其他引擎的表现，会有较大的区别。 查看存储引擎MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL5.6.4，可以使用： 1SHOW ENGINES 乐观锁用数据版本(Version)记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库增加一个数字类型的“version”字段来实现。当读数据时，将version字段的值一同读出，数据每更新一次，对此version值加1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次读取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 举例 数据库表设计 三个字段，分别是id、value、version 1select id,value,version from TABLE where id=#&#123;id&#125; 每次更新表中的value字段时，为了防止发生冲突，需要这样操作 123update TABLEset value=2,version=version+1where id=#&#123;id&#125; and version=#&#123;version&#125;; 悲观锁与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中synchronized很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。 说到这里，由悲观锁涉及到的另外两个概念就出来了，他们就是共享锁与排它锁。共享锁和排它锁是悲观锁的不同实现，它俩都属于悲观锁的范畴。 使用排它锁举例： 要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作时，MySQL会立刻将结果进行提交。 我们可以使用命令设置MySQL为非autocommit模式： 1234567891011121314151617181920212223set autocommit=0;# 设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：# 1. 开始事务begin;/begin work;/start transaction; (三者选一就可以)# 2. 查询表信息select status from TABLE where id=1 for update;# 3. 插入一条数据insert into TABLE (id,value) values (2,2);# 4. 修改数据为update TABLE set value=2 where id=1;# 5. 提交事务commit;/commit work; 共享锁共享锁又称读锁 read lock，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。 如果事务T对数据A加上共享锁后，则其他事务只能对数据A再加共享锁，不能加排他锁。获得共享锁的事务只能读数据，不能修改数据 排他锁排他锁 exclusive lock（也叫writer lock）又称写锁。 排它锁是悲观锁的一种实现，在上面悲观锁也介绍过。 若事务 1 对数据对象A加上X锁，事务 1 可以读A也可以修改A，其他事务不能再对A加任何锁，直到事物 1 释放A上的锁。这保证了其他事务在事物 1 释放A上的锁之前不能再读取和修改A。排它锁会阻塞所有的排它锁和共享锁 读取为什么要加读锁呢：防止数据在被读取的时候被别的线程加上写锁， 使用方式：在需要执行的语句后面加上for update就可以了 行锁行锁又分共享锁和排他锁,由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。 NOTE: 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。 表锁如何加表锁 innodb 的行锁是在有索引的情况下,没有索引的表是锁定全表的. Innodb中的行锁与表锁 前面提到过，在Innodb引擎中既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候或只锁住一行呢？只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。 死锁死锁（Deadlock） 所谓死锁：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。 下列方法有助于最大限度地降低死锁： 按同一顺序访问对象。 避免事务中的用户交互。 保持事务简短并在一个批处理中。 使用低隔离级别。 使用绑定连接。"},{"title":"如何查看MariaDB bin log","permalink":"https://binchencoder.github.io/2018/09/04/查看MariaDB-binlog/","text":"MariaDB bin log今天在学习MariaDB在产线的部署架构时，重新了解了主从复制的原理，同时产生想查看bin log的好奇心，折腾了一番最终搞定 MariaDB主从复制 MySQL的复制就是基于二进制日志而完成的，其工作原理如下： 当MySQL的Master节点的数据有更改的时候，Master会主动通知Slave，让Slave主动来Master获取二进制日志，于是Slave开启一个I/O thread，向Master请求二进制日志中记录的语句；Master将二进制日志中记录的语句发给Slave，Slave则将这些语句存到中继日志中，进而从中继日志中读取一句，执行一句，直到所有的语句被执行完。而经SQL语句从中继日志中读取出来，再一一执行的进程叫做SQL thread；将这些语句执行完之后，从节点的数据就和主节点的数据相同了，这就是所谓的MySQL主从复制。 查看bin log在我们的一个测试环境上，通过如下命令查看 1234567891011121314151617181920212223242526272829MariaDB [(none)]&gt; show binary logs;1381 - You are not using binary loggingMariaDB [(none)]&gt; show variables like &apos;log_bin&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | OFF |+---------------+-------+错误原因：测试环境中部署的实例没有开启bin logMariaDB [(none)]&gt; set global log_bin_trust_function_creators=1;MariaDB [(none)]&gt; show variables like &apos;log_bin_trust_function_creators&apos;;+---------------------------------+-------+| Variable_name | Value |+---------------------------------+-------+| log_bin_trust_function_creators | ON |+---------------------------------+-------+这样添加了参数以后，如果mysqld重启，那个参数又会消失，因此记得在my.cnf配置文件中添加：log_bin_trust_function_creators=1log_bin=mysql_bin添加参数之后重启mysql 123456MariaDB [(none)]&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql_bin.000001 | 217795 |+------------------+-----------+ 123456789101112131415[root@mariadb bin]# mysqlbinlog –no-defaults mysql-bin.00001;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;mysqlbinlog: File &apos;&apos; not found (Errcode: 2)DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 遗留问题从上面Mariadb复制原理中我认为bin log记录的master上执行的sql语句，但是为什么bin log看不到呢？"},{"title":"使用正则引发的血案","permalink":"https://binchencoder.github.io/2018/09/01/使用正则引发的血案/","text":"正则表达式正则表达式, 一个十分古老而又强大的文本处理工具, 仅仅用一段非常简短的表达式语句, 便能够快速实现一个非常复杂的业务逻辑. 熟练地掌握正则表达式的话, 能够使你的开发效率得到极大的提升. 对于一些简单的表单式语句我们可以自己编写, 但是复杂一些并且通用的表达式我们往往会从网上直接拷贝来用. 经过大部分人实践过的一般不会出现问题, 但是偶尔也会踩坑. 最近我就在这个上面掉进了深坑. 案发最近产线上的一个服务连续两天出现问题, 现象就是访问出现 “502 Bad Gateway” 错误. 这个服务是部署在Tomcat下的, 字面上理解就是网关出现问题了, 第一次出现问题后为了紧急修复就直接重启了服务器, 重启后就正常了. 这次事故就这样草草收场，没有留下任何有用的日志信息用来分析, 就没有继续追查下去了. 偷懒是会受到惩罚的. 果不其然, 第二天问题继续出现, 并且还引起了其他的故障. 有了前车之鉴, 这一次受到了足够重视. 为了尽快恢复服务, 重启了部分节点用来恢复产线服务. 留了一个故障节点来断案. 断案排查思路 系统本身代码有问题, 如果是这样, 通过查看日志应该能发现集中的日志. 但是却没有, 初步排除代码逻辑处理错误 内部下游系统的问题导致的雪崩效应, 我们联系了内部下游系统观察了他们的监控，发现一起正常。可以排除下游系统故障对我们的影响 机器本身的问题, 查看机器监控, 排除机器故障问题。 即通过上述方法没有直接定位到问题。 解决方案之前为了快速恢复服务, 我们留下了一个故障节点, 从产线上摘除, 重启了其他节点恢复服务. 下面通过jstack来分析故障 查看当前Tomcat线程pid 12[root@xxx ~]# ps -ef | grep tomcatroot 142 1 0 Aug20 ? 02:46:26 /usr/local/jdk/jre/bin/java -Djava.util.logging.config.file=/usr/local/tomcat_xxx/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/tomcat_xxx/ -server -Xmx512m -Xms512m -XX:NewSize=64m -XX:MaxNewSize=128m -Djava.library.path=/usr/local/apr/lib -Dsun.lang.ClassLoader.allowArraySyntax=true -Djava.net.preferIPv4Stack=true -XX:PermSize=64M -XX:MaxPermSize=378m -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7080 -Dcom.sun.management.jmxremote -classpath /usr/local/tomcat_igoal/bin/bootstrap.jar -Dcatalina.base=/usr/local/tomcat_igoal -Dcatalina.home=/usr/local/tomcat_igoal -Djava.io.tmpdir=/usr/local/tomcat_igoal/temp org.apache.catalina.startup.Bootstrap start 打印jstack日志 1[root@xxx ~]# jstack -l 142 &gt; /tmp/jstack.txt jstack.txt 文件中的内容很多， 根据关键字(程序中的包名或者类名 等) 找到匹配的内容分析线程状态 如何分析线程状态，可以查看我博客中的一篇文章 Thread State 我通过查找 ‘xxx’ 关键字找到很多内容， 但是有些是正常的，就直接过滤掉。最后找到这样一段内容，发现jstack日志中大量重复出现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146&quot;http-192.168.0.185-12491-600&quot; #4971 daemon prio=5 os_prio=0 tid=0x00007f59a0334000 nid=0x1e7e runnable [0x00007f58c7ffc000] java.lang.Thread.State: RUNNABLE at java.util.regex.Pattern$5.isSatisfiedBy(Pattern.java:5251) at java.util.regex.Pattern$5.isSatisfiedBy(Pattern.java:5251) at java.util.regex.Pattern$CharProperty.match(Pattern.java:3776) at java.util.regex.Pattern$Curly.match(Pattern.java:4227) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.matchInit(Pattern.java:4804) at java.util.regex.Pattern$Prolog.match(Pattern.java:4741) at java.util.regex.Pattern$Begin.match(Pattern.java:3525) at java.util.regex.Matcher.match(Matcher.java:1270) at java.util.regex.Matcher.matches(Matcher.java:604) at com.xxx.xxx.util4sysmng.ValidateUtil.checkEmail(ValidateUtil.java:30) at com.xxx.xxx.register.action.RegisterController.regAccountSendVcode(RegisterController.java:538) at com.xxx.xxx.register.action.RegisterController$$FastClassByCGLIB$$58ed8719.invoke(&lt;generated&gt;) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191) at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:689) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:80) at com.xxx.prometheus.aspect.PrometheusAspect.process(PrometheusAspect.java:35) at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:65) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:161) at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:124) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:90) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:622) at com.xxx.xxx.register.action.RegisterController$$EnhancerByCGLIB$$972a02bd.regAccountSendVcode(&lt;generated&gt;) at sun.reflect.GeneratedMethodAccessor124.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:212) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:126) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:96) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:617) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:578) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:900) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:827) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778) at javax.servlet.http.HttpServlet.service(HttpServlet.java:617) at javax.servlet.http.HttpServlet.service(HttpServlet.java:723) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at com.xxx.xxx.sysmng.filter.SysmngSecurityFilter.doFilter(SysmngSecurityFilter.java:46) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:615) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:861) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:606) at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) at java.lang.Thread.run(Thread.java:745) 通过上面这段内容分析，在正则验证时出现大量线程等待，一直消耗系统CPU，最终造成服务处于假死状态，无法响应。 定位到具体的代码，经过测试 确认是验证Email的一个正则表达式有问题。代码中使用的Email正则表达式是这样写的：1^([a-z0-9A-Z]+[-|\\\\._]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\\\.)+[a-zA-Z]&#123;2,&#125;$ 测试代码123456789@Testpublic void testRegexFailed() &#123; String email = &quot;dnjnfslkffkjkjkslioeo9edkdjfks&quot;; String regex = &quot;^([a-z0-9A-Z]+[-|_|\\\\\\\\.]?)*[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\\\\\\\.)+[a-z0-9A-Z]&#123;2,&#125;$&quot;; Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(email); System.out.println(email + &quot; : &quot; + matcher.matches());&#125; 这段代码会出现死循环，使我电脑消耗CPU急剧增加，我在测试过程中打印了该进程消耗系统资源的数据1234567891011121314151617181920212223242526chenbin@chenbin-ThinkPad:~$ jps 23617 Launcher 21422 JUnitStarter chenbin@chenbin-ThinkPad:~$ top -Hp 21422Threads: 16 total, 1 running, 15 sleeping, 0 stopped, 0 zombie %Cpu(s): 30.8 us, 3.6 sy, 0.0 ni, 65.4 id, 0.1 wa, 0.0 hi, 0.1 si, 0.0 st KiB Mem : 7861372 total, 202784 free, 6652340 used, 1006248 buff/cache KiB Swap: 8076284 total, 3543620 free, 4532664 used. 872480 avail Mem PID USER PR NI VIRT RES SHR S% CPU% MEM TIME+ COMMAND 21425 chenbin 20 0 4468684 100360 18136 R 99.7 1.3 0:22.25 java 21422 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21434 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21435 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21436 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21437 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21438 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21439 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21440 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21441 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21442 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21443 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.88 java 21444 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.72 java 21445 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.09 java 21446 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21447 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 测试中发现 在输入的字符串比较短的时候，验证没有问题。但是在输入字符较长，并且不符合email规则的时候，会出现死循环。如果输入过长，但是符合这个email规则，也不会有这个问题！ 结案最后我们只能修改代码，替换这个正则表达式。因为这是通过的表达式，而且比较复杂，我们就没有造轮子。直接在网上找的, 经过验证，发现这个网站提供的正则比较靠谱Java Email Address Validation END能匹配空字符串的子匹配不要循环无限次。如果括号内的子表达式中的每一部分都可以匹配 0 次，而这个括号整体又可以匹配无限次，匹配过程中可能死循环。虽然现在有些正则表达式引擎已经通过办法避免了这种情况出现死循环了，比如 .NET 的正则表达式，但是我们仍然应该尽量避免出现这种情况。如果我们在写表达式时遇到了死循环，也可以从这一点入手。 正则表达式虽然使用起来很方便, 但是一定要慎用."},{"title":"Thread State","permalink":"https://binchencoder.github.io/2018/08/31/Thread-State/","text":"Java 线程状态分析Java线程的生命周期中, 存在着六种状态. 在Thread类里有一个枚举类型State, 定义了线程的几种状态. 下图比较清晰的展示了这六种状态之间的转换关系 NEW: 线程创建之后，但是还没有启动(not yet started)。这时候它的状态就是NEW RUNNABLE: 正在Java虚拟机下跑任务的线程的状态。在RUNNABLE状态下的线程可能会处于等待状态， 因为它正在等待一些系统资源的释放，比如IO BLOCKED: 阻塞状态，等待锁的释放，比如线程A进入了一个synchronized方法，线程B也想进入这个方法，但是这个方法的锁已经被线程A获取了，这个时候线程B就处于BLOCKED状态 WAITING: 等待状态，处于等待状态的线程是由于执行了3个方法中的任意方法。 Object的wait方法，并且没有使用timeout参数; Thread的join方法，没有使用timeout参数 LockSupport的park方法。 处于waiting状态的线程会等待另外一个线程处理特殊的行为。 再举个例子，如果一个线程调用了一个对象的wait方法，那么这个线程就会处于waiting状态直到另外一个线程调用这个对象的notify或者notifyAll方法后才会解除这个状态 TIMED_WAITING: 有等待时间的等待状态，比如调用了以下几个方法中的任意方法，并且指定了等待时间，线程就会处于这个状态。 Thread.sleep方法 Object的wait方法，带有时间 Thread.join方法，带有时间 LockSupport的parkNanos方法，带有时间 LockSupport的parkUntil方法，带有时间 TERMINATED: 线程中止的状态，这个线程已经完整地执行了它的任务 NEW StateNEW状态比较简单，实例化一个线程之后，并且这个线程没有开始执行，这个时候的状态就是NEW：12Thread thread = new Thread();System.out.println(thread.getState()); // NEW RUNNABLE State正在运行的状态123456789Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i = 0; i &lt; Integer.MAX_VALUE; i ++) &#123; System.out.println(i); &#125; &#125;&#125;, &quot;RUNNABLE-Thread&quot;);thread.start(); 使用jstack查看线程状态： 123456789101112131415161718192021&quot;RUNNABLE-Thread&quot; #10 prio=5 os_prio=31 tid=0x00007f8e04981000 nid=0x4f03 runnable [0x000070000124c000] java.lang.Thread.State: RUNNABLE at java.io.FileOutputStream.writeBytes(Native Method) at java.io.FileOutputStream.write(FileOutputStream.java:315) at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) - locked &lt;0x000000079764cc50&gt; (a java.io.BufferedOutputStream) at java.io.PrintStream.write(PrintStream.java:482) - locked &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221) at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:291) at sun.nio.cs.StreamEncoder.flushBuffer(StreamEncoder.java:104) - locked &lt;0x0000000797604d78&gt; (a java.io.OutputStreamWriter) at java.io.OutputStreamWriter.flushBuffer(OutputStreamWriter.java:185) at java.io.PrintStream.write(PrintStream.java:527) - eliminated &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at java.io.PrintStream.print(PrintStream.java:597) at java.io.PrintStream.println(PrintStream.java:736) - locked &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at study.thread.ThreadStateTest$1.run(ThreadStateTest.java:23) at java.lang.Thread.run(Thread.java:745) BLOCKED State线程A和线程B都需要持有lock对象的锁才能调用方法。如果线程A持有锁，那么线程B处于BLOCKED状态；如果线程B持有锁，那么线程A处于BLOCKED状态。例子中使用Thread.sleep方法主要是用于调试方便：1234567891011121314151617181920212223242526272829final Object lock = new Object();Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; invoke&quot;); try &#123; Thread.sleep(20000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;BLOCKED-Thread-A&quot;);Thread threadB = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; invoke&quot;); try &#123; Thread.sleep(20000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;BLOCKED-Thread-B&quot;);threadA.start();threadB.start(); 使用jstack查看线程状态。由于线程A先执行，线程B后执行，而且线程A执行后调用了Thread.sleep方法，所以线程A会处于TIMED_WAITING状态，线程B处于BLOCKED状态：123456789101112&quot;BLOCKED-Thread-B&quot; #11 prio=5 os_prio=31 tid=0x00007fa7db8ff000 nid=0x5103 waiting for monitor entry [0x000070000134f000] java.lang.Thread.State: BLOCKED (on object monitor) at study.thread.ThreadStateTest$3.run(ThreadStateTest.java:50) - waiting to lock &lt;0x0000000795a03bf8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)&quot;BLOCKED-Thread-A&quot; #10 prio=5 os_prio=31 tid=0x00007fa7db15a000 nid=0x4f03 waiting on condition [0x000070000124c000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$2.run(ThreadStateTest.java:39) - locked &lt;0x0000000795a03bf8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745) WAITING StateObject的wait方法、Thread的join方法以及Conditon的await方法都会产生WAITING状态。 1.没有时间参数的Object的wait方法1234567891011121314151617181920212223242526272829final Object lock = new Object();Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; lock.wait(); System.out.println(&quot;wait over&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;WAITING-Thread-A&quot;);Thread threadB = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.notifyAll(); &#125; &#125;&#125;, &quot;WAITING-Thread-B&quot;);threadA.start();threadB.start(); WAITING-Thread-A调用了lock的wait，处于WAITING状态：123456789101112131415&quot;WAITING-Thread-B&quot; #11 prio=5 os_prio=31 tid=0x00007f8de992d800 nid=0x5103 waiting on condition [0x000070000134f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$5.run(ThreadStateTest.java:84) - locked &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)&quot;WAITING-Thread-A&quot; #10 prio=5 os_prio=31 tid=0x00007f8dea193000 nid=0x4f03 in Object.wait() [0x000070000124c000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Object.wait(Object.java:502) at study.thread.ThreadStateTest$4.run(ThreadStateTest.java:71) - locked &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745) 2.Thread的join方法1234567891011121314151617Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread-A over&quot;); &#125;&#125;, &quot;WAITING-Thread-A&quot;);threadA.start();try &#123; threadA.join();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 主线程main处于WAITING状态：12345678910111213141516171819&quot;WAITING-Thread-A&quot; #10 prio=5 os_prio=31 tid=0x00007fd2d5100000 nid=0x4e03 waiting on condition [0x000070000124c000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$6.run(ThreadStateTest.java:103) at java.lang.Thread.run(Thread.java:745)&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fd2d3815000 nid=0x1003 in Object.wait() [0x0000700000182000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795a03ec0&gt; (a java.lang.Thread) at java.lang.Thread.join(Thread.java:1245) - locked &lt;0x0000000795a03ec0&gt; (a java.lang.Thread) at java.lang.Thread.join(Thread.java:1319) at study.thread.ThreadStateTest.WAITING_join(ThreadStateTest.java:118) at study.thread.ThreadStateTest.main(ThreadStateTest.java:13) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) 3.没有时间参数的Condition的await方法 Condition的await方法跟Obejct的wait方法原理是一样的，故也是WAITING状态 TIMED_WAITING StateTIMED_WAITING状态跟TIMEING状态类似，是一个有等待时间的等待状态，不会一直等待下去。 最简单的TIMED_WAITING状态例子就是Thread的sleep方法：123456789101112131415161718Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread-A over&quot;); &#125;&#125;, &quot;WAITING-Thread-A&quot;);threadA.start();try &#123; Thread.sleep(5000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(threadA.getState()); // TIMED_WAITING 或者是Object的wait方法带有时间参数、Thread的join方法带有时间参数也会让线程的状态处于TIMED_WAITING状态。 TERMINATED State线程终止的状态，线程执行完成，结束生命周期。12345678Thread threadA = new Thread();threadA.start();try &#123; Thread.sleep(5000l);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(threadA.getState()); // TERMINATED END了解线程的状态可以分析一些问题。 比如线程处于BLOCKED状态，这个时候可以分析一下是不是lock加锁的时候忘记释放了，或者释放的时机不对。导致另外的线程一直处于BLOCKED状态。 比如线程处于WAITING状态，这个时候可以分析一下notifyAll或者signalAll方法的调用时机是否不对。 java自带的jstack工具可以分析查看线程的状态、优先级、描述等具体信息。"},{"title":"UsefulScripts-Java脚本","permalink":"https://binchencoder.github.io/2018/07/22/UsefulScripts-Java脚本/","text":"show-busy-java-threads.sh 用法 示例 贡献者 show-duplicate-java-classes 用法 JDK开发场景使用说明 对于一般的工程 对于Web工程 Android开发场景使用说明 示例 贡献者 find-in-jars.sh 用法 示例 参考资料 show-busy-java-threads.sh 用于快速排查Java的CPU性能问题(top us值过高)，自动查出运行的Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用。 PS，如何操作可以参见@bluedavy的《分布式Java应用》的【5.1.1 cpu消耗分析】一节，说得很详细： top命令找出有问题Java进程及线程id： 开启线程显示模式 按CPU使用率排序 记下Java进程id及其CPU高的线程id 用进程id作为参数，jstack有问题的Java进程 手动转换线程id成十六进制（可以用printf %x 1234） 查找十六进制的线程id（可以用grep） 查看对应的线程栈 查问题时，会要多次这样操作以确定问题，上面过程太繁琐太慢了。 用法12345678910111213show-busy-java-threads.sh# 从 所有的 Java进程中找出最消耗CPU的线程（缺省5个），打印出其线程栈。show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt;show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt; -p &lt;指定的Java Process&gt;############################### 注意：############################### 如果Java进程的用户 与 执行脚本的当前用户 不同，则jstack不了这个Java进程。# 为了能切换到Java进程的用户，需要加sudo来执行，即可以解决：sudo show-busy-java-threads.sh 示例1234567891011121314151617181920212223242526272829$ show-busy-java-threads.sh[1] Busy(57.0%) thread(23355/0x5b3b) stack of java process(23269) under user(admin):\"pool-1-thread-1\" prio=10 tid=0x000000005b5c5000 nid=0x5b3b runnable [0x000000004062c000] java.lang.Thread.State: RUNNABLE at java.text.DateFormat.format(DateFormat.java:316) at com.xxx.foo.services.common.DateFormatUtil.format(DateFormatUtil.java:41) at com.xxx.foo.shared.monitor.schedule.AppMonitorDataAvgScheduler.run(AppMonitorDataAvgScheduler.java:127) at com.xxx.foo.services.common.utils.AliTimer$2.run(AliTimer.java:128) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)[2] Busy(26.1%) thread(24018/0x5dd2) stack of java process(23269) under user(admin):\"pool-1-thread-2\" prio=10 tid=0x000000005a968800 nid=0x5dd2 runnable [0x00000000420e9000] java.lang.Thread.State: RUNNABLE at java.util.Arrays.copyOf(Arrays.java:2882) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:100) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:572) at java.lang.StringBuffer.append(StringBuffer.java:320) - locked &lt;0x00000007908d0030&gt; (a java.lang.StringBuffer) at java.text.SimpleDateFormat.format(SimpleDateFormat.java:890) at java.text.SimpleDateFormat.format(SimpleDateFormat.java:869) at java.text.DateFormat.format(DateFormat.java:316) at com.xxx.foo.services.common.DateFormatUtil.format(DateFormatUtil.java:41) at com.xxx.foo.shared.monitor.schedule.AppMonitorDataAvgScheduler.run(AppMonitorDataAvgScheduler.java:126) at com.xxx.foo.services.common.utils.AliTimer$2.run(AliTimer.java:128) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)... 上面的线程栈可以看出，CPU消耗最高的2个线程都在执行java.text.DateFormat.format，业务代码对应的方法是shared.monitor.schedule.AppMonitorDataAvgScheduler.run。可以基本确定： AppMonitorDataAvgScheduler.run调用DateFormat.format次数比较频繁。 DateFormat.format比较慢。（这个可以由DateFormat.format的实现确定。） 多个执行几次show-busy-java-threads.sh，如果上面情况高概率出现，则可以确定上面的判定。# 因为调用越少代码执行越快，则出现在线程栈的概率就越低。 分析shared.monitor.schedule.AppMonitorDataAvgScheduler.run实现逻辑和调用方式，以优化实现解决问题。 贡献者 silentforce改进此脚本，增加对环境变量JAVA_HOME的判断。 #15 liuyangc3 优化性能，通过read -a简化反复的awk操作 #51 发现并解决jstack非当前用户Java进程的问题 #50 show-duplicate-java-classes找出Java Lib（Java库，即Jar文件）或Class目录（类目录）中的重复类。 Java开发的一个麻烦的问题是Jar冲突（即多个版本的Jar），或者说重复类。会出NoSuchMethod等的问题，还不见得当时出问题。找出有重复类的Jar，可以防患未然。 用法 通过脚本参数指定Libs目录，查找目录下Jar文件，收集Jar文件中Class文件以分析重复类。可以指定多个Libs目录。 注意，只会查找这个目录下Jar文件，不会查找子目录下Jar文件。因为Libs目录一般不会用子目录再放Jar，这样也避免把去查找不期望Jar。 通过-c选项指定Class目录，直接收集这个目录下的Class文件以分析重复类。可以指定多个Class目录。 1234567891011# 查找当前目录下所有Jar中的重复类show-duplicate-java-classes# 查找多个指定目录下所有Jar中的重复类show-duplicate-java-classes path/to/lib_dir1 /path/to/lib_dir2# 查找多个指定Class目录下的重复类。 Class目录 通过 -c 选项指定show-duplicate-java-classes -c path/to/class_dir1 -c /path/to/class_dir2# 查找指定Class目录和指定目录下所有Jar中的重复类的Jarshow-duplicate-java-classes path/to/lib_dir1 /path/to/lib_dir2 -c path/to/class_dir1 -c path/to/class_dir2 JDK开发场景使用说明以Maven作为构建工程示意过程。 对于一般的工程123456# 在项目模块目录下执行，拷贝依赖Jar到目录target/dependency下$ mvn dependency:copy-dependencies -DincludeScope=runtime...# 检查重复类$ show-duplicate-java-classes target/dependency... 对于Web工程对于Web工程，即war maven模块，会打包生成war文件。 123456789# 在war模块目录下执行，生成war文件$ mvn install...# 解压war文件，war文件中包含了应用的依赖的Jar文件$ unzip target/*.war -d target/war...# 检查重复类$ show-duplicate-java-classes -c target/war/WEB-INF/classes target/war/WEB-INF/lib... Android开发场景使用说明Android开发，有重复类在编译打包时会报[Dex Loader] Unable to execute dex: Multiple dex files define Lorg/foo/xxx/Yyy。 但只会给出一个重复类名，如果重复类比较多时，上面打包/报错/排查会要进行多次，而Android的打包比较费时，这个过程比较麻烦，希望可以一次把所有重复类都列出来，一起排查掉。 以Gradle作为构建工程示意过程。 在App的build.gradle中添加拷贝库到目录build/dependencies下。 12345678910task copyDependencies(type: Copy) &#123; def dest = new File(buildDir, \"dependencies\") // clean dir dest.deleteDir() dest.mkdirs() // fill dir with dependencies from configurations.compile into dest&#125; 123456# 拷贝依赖$ ./gradlew app:copyDependencies...# 检查重复类$ show-duplicate-java-classes app/build/dependencies... 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ show-duplicate-java-classes WEB-INF/libCOOL! No duplicate classes found!================================================================================class paths to find:================================================================================1 : WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar2 : WEB-INF/lib/misc.htmlparser-0.0.0.jar3 : WEB-INF/lib/normandy.client-1.0.2.jar...$ show-duplicate-java-classes -c WEB-INF/classes WEB-INF/libFound duplicate classes in below class path:1 (293@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.orm-2.5.6.SEC02.jar2 (2@3): WEB-INF/lib/servlet-api-3.0-alpha-1.jar WEB-INF/lib/jsp-api-2.1-rev-1.jar WEB-INF/lib/jstl-api-1.2-rev-1.jar3 (104@2): WEB-INF/lib/commons-io-2.2.jar WEB-INF/lib/jakarta.commons.io-2.0.jar4 (6@3): WEB-INF/lib/jakarta.commons.logging-1.1.jar WEB-INF/lib/commons-logging-1.1.1.jar WEB-INF/lib/org.slf4j.jcl104-over-slf4j-1.5.6.jar5 (344@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar...================================================================================Duplicate classes detail info:================================================================================1 (293@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.orm-2.5.6.SEC02.jar 1 org/springframework/orm/toplink/TopLinkTemplate$13.class 2 org/springframework/orm/hibernate3/HibernateTemplate$24.class 3 org/springframework/orm/jpa/vendor/HibernateJpaDialect.class 4 org/springframework/orm/hibernate3/TypeDefinitionBean.class 5 org/springframework/orm/hibernate3/SessionHolder.class ...2 (2@3): WEB-INF/lib/servlet-api-3.0-alpha-1.jar WEB-INF/lib/jsp-api-2.1-rev-1.jar WEB-INF/lib/jstl-api-1.2-rev-1.jar 1 javax/servlet/ServletException.class 2 javax/servlet/ServletContext.class3 (104@2): WEB-INF/lib/commons-io-2.2.jar WEB-INF/lib/jakarta.commons.io-2.0.jar 1 org/apache/commons/io/input/ProxyReader.class 2 org/apache/commons/io/output/FileWriterWithEncoding.class 3 org/apache/commons/io/output/TaggedOutputStream.class 4 org/apache/commons/io/filefilter/NotFileFilter.class 5 org/apache/commons/io/filefilter/TrueFileFilter.class ......================================================================================class paths to find:================================================================================1 : WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar2 : WEB-INF/lib/misc.htmlparser-0.0.0.jar3 : WEB-INF/lib/normandy.client-1.0.2.jar4 : WEB-INF/lib/xml.xmlgraphics__batik-css-1.7.jar-1.7.jar5 : WEB-INF/lib/jakarta.ecs-1.4.2.jar... 贡献者tgic提供此脚本。友情贡献者的链接commandlinefu.cn|微博linux命令行精选 find-in-jars.sh在当前目录下所有jar文件里，查找类或资源文件。 用法1234find-in-jars.sh 'log4j\\.properties'find-in-jars.sh 'log4j\\.xml$' -d /path/to/find/directoryfind-in-jars.sh log4j\\\\.xmlfind-in-jars.sh 'log4j\\.properties|log4j\\.xml' 注意，后面Pattern是grep的 扩展正则表达式。 示例123$ ./find-in-jars 'Service.class$'./WEB-INF/libs/spring-2.5.6.SEC03.jar!org/springframework/stereotype/Service.class./rpc-benchmark-0.0.1-SNAPSHOT.jar!com/taobao/rpc/benchmark/service/HelloService.class 参考资料在多个Jar(Zip)文件查找Log4J配置文件的Shell命令行"},{"title":"gRPC Status and HTTP Code Relation","permalink":"https://binchencoder.github.io/2018/07/22/GRPC-Status-HTTP-Status/","text":"Status.INVALID_ARGUMENT [400] Status.OK [200] Status.CANCELLED [408] Status.UNKNOWN [500] Status.DEADLINE_EXCEEDED [408] Status.NOT_FOUND [404] Status.ALREADY_EXISTS [409] Status.PERMISSION_DENIED [403] Status.RESOURCE_EXHAUSTED [403] Status.FAILED_PRECONDITION [412] Status.ABORTED [409] Status.OUT_OF_RANGE [400] Status.UNIMPLEMENTED [501] Status.INTERNAL [500] Status.UNAVAILABLE [503] Status.DATA_LOSS [500] Status.UNAUTHENTICATED [401]"},{"title":"Hexo配合搭建github个人主页","permalink":"https://binchencoder.github.io/2018/07/21/Hexo搭建github主页/","text":"前言“工欲善其事，必先利其器”，在搭建个人博客的过程中，我深刻体会到这句话的含义。虽然早就决定了要搭建个人博客，但是我并没有草草动手，而是提前做了大量的调研工作，包括采用哪种博客系统、选择哪种主题、怎么购买并绑定个性域名等等。事实证明，正因为前期的充分准备，搭建过程才能按部就班地进行。下面先介绍为何选择GitHub Pages和Hexo来搭建博客 准备 Node js环境 Git环境 检查环境安装是否正确12345678chenbin@chenbin-ThinkPad:~$ node -vv8.9.4chenbin@chenbin-ThinkPad:~$ npm -v5.6.0chenbin@chenbin-ThinkPad:~$ git --versiongit version 2.17.1 如果结果如上, 则说明安装正确， 可以进行下一步了。 如果不正确， 则需要回头检查自己的安装过程 Install Hexo1$ npm install -g hexo-cli Link:https://hexo.io/zh-cn/docs/index.html 建站安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install NOTE: Init 必须是完全空的目录. 不能存在任何文件, 包括隐藏文件 新建完成后，指定文件夹的目录如下：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 查看建站效果自动根据当前目录下文件,生成静态网页1hexo g 运行本地服务, 出现以下结果说明本地服务运行成功. 这时就可以在浏览器输入http://localhost:4000/ 就可以看到效果了.12345hexo schenbin@chenbin-ThinkPad:~/.../github-workspace/Hexo-code$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 效果图: DeployHexo提供了快速方便的一键部署功能，让您只需一条命令就能将网站部署到服务器上。 1$ hexo deploy 在开始之前，您必须先在 _config.yml 中修改参数，一个正确的部署配置中至少要有 type 参数，例如：12deploy: type: git 您可同时使用多个 deployer，Hexo 会依照顺序执行每个 deployer。12345deploy:- type: git repo:- type: heroku repo: 缩进 YAML依靠缩进来确定元素间的从属关系。因此，请确保每个deployer的缩进长度相同，并且使用空格缩进。 详细说明请查看:https://hexo.io/zh-cn/docs/configuration.html Git Deploy以下是我在本地使用Git Deploy配置的例子:123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: https://github.com/binchencoder/binchencoder.github.io.git branch: master Install Git Deployer安装 hexo-deployer-git1$ npm install hexo-deployer-git --save 安装成功之后就可以使用Git将网站部署到指定的服务器上1234567891011chenbin@chenbin-ThinkPad:~/.../github-workspace/Hexo-code$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...位于分支 master无文件要提交，干净的工作区To https://github.com/binchencoder/binchencoder.github.io.git 8a8903c..dac6bed HEAD -&gt; master分支 &apos;master&apos; 设置为跟踪来自 &apos;https://github.com/binchencoder/binchencoder.github.io.git&apos; 的远程分支 &apos;master&apos;。INFO Deploy done: git 出现如上结果，就大功告成了。 Hexo Hello-World网站已经部署到Git服务上。就可以通过https://binchencode.github.io 地址访问部署的网站了"},{"title":"Hello World","permalink":"https://binchencoder.github.io/2018/07/21/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"}]}