{"pages":[],"posts":[{"title":"Docular","date":"2020-07-14T09:00:08.000Z","updated":"2020-07-14T09:08:59.688Z","comments":true,"path":"2020/07/14/Docular/","permalink":"https://binchencoder.github.io/2020/07/14/Docular/","excerpt":"","text":"DocularDocular是一个个人文档服务，它提供了一个本地HTTP服务器来服务给定文件夹中的文档。该文件夹包含以下支持的文件格式：HTML，MarkDown，MAFF InstallDocular 在Linux 和 Mac 平台上都能很好的支持 Download Linux Docular Linux 1sudo dpkg -i docular_1.0_amd64.deb Mac Docular Mac NOTE Mac上安装稍微麻烦一点，需要将webstatic 目录下载到本地，然后在运行时指定 -webstatic Launch123456789101112131415chenbin@chenbin-ThinkPad:~/$ docular -hDocular server.Usage: docular-server [options]Options: -allow-external Allow external access -doc-dir string The doc directory path. -port int The http port. (default 3455) -webstatic string The web static directory. (default &quot;/usr/share/docular/webstatic&quot;) 运行docular需要指定doc-dir，也就是你想预览的文件夹 可同时运行多个docular服务，需要制定port ScreenshotsTODO References https://github.com/binchencoder/docular https://github.com/russross/blackfriday"},{"title":"多线程 — 概述及底层实现机制浅析","date":"2020-04-15T08:00:08.000Z","updated":"2020-04-15T08:46:27.495Z","comments":true,"path":"2020/04/15/多线程 — 概述及底层实现机制浅析/","permalink":"https://binchencoder.github.io/2020/04/15/多线程 — 概述及底层实现机制浅析/","excerpt":"","text":"多线程多线程是为了使得多个线程并行的工作以完成多项任务, 以提高系统的效率. 线程是在同一时间需要完成多项任务的时候被实现的. 什么是线程、进程在讨论多线程之前, 我们需要先认识一下, 进程、线程, 以及相关值得注意的问题. 我们一起先来读一个有趣的故事《进程与线程的一个简单解释》, 浅显易懂, 生动形象的解释了多线程相关的很多典型问题. 进程程序的一次执行 进程是计算机中的程序关于某数据集合上的一次运行活动. 是系统进行资源分配和调度的基本单位, 是操作系统结构的基础. 进程是计算机中已运行程序的实体. 其本身并不是内部运行单位, 是线程的容器 线程CPU的基本调度单位 线程是操作系统能够进行运算调度的最小单位. 线程是一组指令的集合它被包含在进程之中, 是进程中的实际运作单位. 一条线程指的是进程中一个单一顺序的控制流, 一个进程中可以并发多个线程, 每条线程并行执行不同的任务. 线程是独立调度和分派的基本单位. 同一进程中的多条线程将共享该进程中的全部系统资源, 但是自有调度堆栈和寄存器环境. 线程、进程的不同 主线程在程序中的地位和其他线程不同，它是其他线程最终的父线程，且所有界面的显示操作即AppKit或 UIKit的操作必须在主线程进行 进程和线程都是操作系统的概念。进程是应用程序的执行实例，每个进程是由私有的虚拟地址空间、代码、数据和其它各种系统资源组成 线程和进程十分相似，不同的只是线程比进程小。首先，线程采用了多个线程可共享资源的设计思想；例如，它们的操作大部分都是在同一地址空间进行的。其次，从一个线程切换到另一线程所花费的代价比进程低。再次，进程本身的信息在内存中占用的空间比线程大，因此线程更能允分地利用内存 线程是进程的一部分CPU调度的是线程系统为进程分配资源，不对线程分配资源 线程、进程的关系一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。 资源分配给进程，同一进程的所有线程共享该进程的所有资源。 处理机分给线程，即真正在处理机上运行的是线程。 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步 References http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html"},{"title":"linux top命令VIRT,RES,SHR,DATA的含义","date":"2020-01-03T08:23:08.000Z","updated":"2020-01-03T10:24:56.010Z","comments":true,"path":"2020/01/03/linux top命令VIRT,RES,SHR,DATA的含义/","permalink":"https://binchencoder.github.io/2020/01/03/linux top命令VIRT,RES,SHR,DATA的含义/","excerpt":"","text":"一、VIRTvirtual memory usage 虚拟内存 1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等2、假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量 VIRT = SWAP + RES 二、RESresident memory usage 常驻内存 1、进程当前使用的内存大小，但不包括swap out2、包含其他进程的共享3、如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反4、关于库占用内存的情况，它只统计加载的库文件所占内存大小 RES = CODE + DATA 三、SHRshared memory 共享内存 1、除了自身进程的共享内存，也包括其他进程的共享内存2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小3、计算某个进程所占的物理内存大小公式：RES – SHR4、swap out后，它将会降下来 四、DATA1、数据占用的内存。如果top没有显示，按f键可以显示出来。2、真正的该程序要求的数据空间，是真正在运行中要使用的。 top 运行中可以通过 top 的内部命令对进程的显示方式进行控制 Command Description s 改变画面更新频率 l 关闭或开启第一部分第一行 top 信息的表示 t 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示 m 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示 N 以 PID 的大小的顺序排列表示进程列表 P 以 CPU 占用率大小的顺序排列进程列表 M 以内存占用率大小的顺序排列进程列表 h 显示帮助 n 设置在进程列表所显示进程的数量 q 退出 top s 改变画面更新周期 默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。 通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定 按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定 按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转"},{"title":"Java面试圣经","date":"2019-12-03T02:00:08.000Z","updated":"2020-04-20T09:35:33.070Z","comments":true,"path":"2019/12/03/Java面试圣经/","permalink":"https://binchencoder.github.io/2019/12/03/Java面试圣经/","excerpt":"","text":"基础篇基本功 面向对象的特征 final, finally, finalize 的区别 https://www.jianshu.com/p/c45b6d782e91 重载和重写的区别 说说反射的用途及实现 equals 与 == 的区别 数据结构 二叉树 链表 集合 List 和 Set 区别 List 和 Map 区别 Arraylist 与 LinkedList 区别 ArrayList 与 Vector 区别 HashMap 和 Hashtable 的区别 HashSet 和 HashMap 区别 HashMap 和 ConcurrentHashMap 的区别 HashMap 的工作原理及代码实现 ConcurrentHashMap 的工作原理及代码实现 HashMap是如何扩容的 HashMap如何避免key碰撞 HashMap死循环问题 进阶篇网络 讲讲TCP/IP https://www.liaoxuefeng.com/wiki/897692888725344/923056618783712 讲讲TCP、UDP、IP https://segmentfault.com/a/1190000020121595 TCP三次握手、四次握手 https://note.youdao.com/ynoteshare1/index.html?id=0e999579be9f295f0d895930c98a67b9&amp;type=note IO Java中IO流的分类 https://www.cnblogs.com/shuaiguoguo/p/8883862.html NIO、BIO、AIO See： https://www.cnblogs.com/zedosu/p/6666984.html BIO：同步阻塞式IO，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 NIO：同步非阻塞式IO，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。 AIO(NIO 2.0)：异步非阻塞式IO，服务器实现模式为一个有效请求一个线程，客户端的IO请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 线程 References Java线程模型 说说 CountDownLatch 原理 CountDownLatch是同步工具类之一，可以指定一个计数值，在并发环境下由线程进行减1操作，当计数值为0之后，被await方法阻塞的线程将会唤醒，实现线程间的同步。 See https://www.jianshu.com/p/7c7a5df5bda6 说说 CyclicBarrier 原理 CyclicBarrier 字面意思是可循环（Cyclic）使用的屏障（Barrier）。它要做的事情是让一组线程到达一个屏障（同步点）时被阻塞，直到最后一个线程到达屏障时候，屏障才会开门。所有被屏障拦截的线程才会运行。 CyclicBarrier是由ReentrantLock可重入锁和Condition共同实现的。 说说 Semaphore 原理 Semaphore也叫信号量, 在JDK1.5被引入, 可以用来控制同时访问特定资源的线程数量, 通过协调各个线程, 以保证合理的使用资源. Semaphore内部维护了一组虚拟的许可, 许可的数量可以通过构造函数的参数指定. 访问特定资源前, 必须使用acquire方法获得许可, 如果许可数量为0, 该线程则一直阻塞, 直到有可用的许可 访问资源后, 使用release释放许可 Semaphore和ReentrantLock类似，获取许可有公平策略和非公平许可策略，默认情况下使用非公平策略 应用场景 : Semaphore可以用来做流量分流，特别是对公共资源有限的场景，比如数据库连接。假设有这个的需求，读取几万个文件的数据到数据库中，由于文件读取是IO密集型任务，可以启动几十个线程并发读取，但是数据库连接数只有10个，这时就必须控制最多只有10个线程能够拿到数据库连接进行操作。这个时候，就可以使用Semaphore做流量控制 说说 Exchanger 原理 说说 CountDownLatch 与 CyclicBarrier 区别 CountDownLatch CyclicBarrier 减计数方式 加计数方式 计算为0时释放所有等待的线程 计数达到指定值时释放所有等待线程 计数为0时，无法重置 计数达到指定值时，计数置为0重新开始 调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响 调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞 不可重复使用 可重复利用 CountDownLatch 强调的是一个线程（或多个）需要等待另外的n个线程干完某件事情之后才能继续执行。 举个例子：有五个人，一个裁判。这五个人同时跑，裁判开始计时，五个人都到终点了，裁判喊停，然后统计这五个人从开始跑到最后一个撞线用了多长时间。 我们实现代码的思路可能是这样：main线程是裁判，5个Worker是跑步的，运动员先准备，裁判喊跑，运动员才开始跑(这是第一次同步，对应begin)。5个人谁跑到终点了，countdown一下，直到5个人全部到达，裁判喊停(这是第二次同步，对应end)，然后算时间。 CyclicBarrier强调的是n个线程，大家相互等待，只要有一个没完成，所有人都得等着。 ThreadLocal 原理分析 用于防止对可变的单实例变量或全局变量进行共享 See https://www.cnblogs.com/micrari/p/6790229.html 讲讲线程池的实现原理 See https://www.jianshu.com/p/87bff5cc8d8c 线程池的几种方式与使用场景 线程的生命周期及几种状态 锁机制 AQS详解 AQS是AbstractQueuedSynchronizer的简称。AQS提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架。AQS为一系列同步器依赖于一个单独的原子变量（state）的同步器提供了一个非常有用的基础。子类们必须定义改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。 See https://www.cnblogs.com/waterystone/p/4920797.html 说说线程安全问题 某个属性是被多线程共享的资源，同时多线程有读写操作，就有可能（注意是有可能）存在线程安全问题。 即使是有多线程对同一个共享资源都有读写，也不能笼统的说就一定存在线程安全问题 要考虑线程安全问题并不代表一定就有线程安全问题。仿佛有点矛盾。判断存不存在线程安全问题，还要根据业务特点和发生问题导致的结果来判断。 volatile 实现原理 如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。这个就是所谓的“可见性”，就是一个线程修改了，其他线程能知道这个操作，这就是可见性。如何实现的呢？volatile修饰的变量在生成汇编代码的时候，会产生一条lock指令，lock前缀的指令在多核处理器下会引发两件事情： 将当前处理器缓存行的数据写回到系统内存； 这个写回内存的操作会使得在其它cpu里缓存了该内存地址的数据无效。 See https://www.cnblogs.com/nevermorewang/p/9864797.html synchronized 实现原理 synchronized是用java的monitor机制来实现的，就是synchronized代码块或者方法进入及退出的时候会生成monitorenter跟monitorexit两条命令。线程执行到monitorenter时会尝试获取对象所对应的monitor所有权，即尝试获取的对象的锁；monitorexit即为释放锁。 synchronized 与 lock 的区别 CAS 乐观锁 乐观锁的业务场景及实现方式 ABA 问题 核心篇数据存储 MySQL 索引使用的注意事项 分库与分表带来的分布式困境与应对之策 说说 SQL 优化之道 负向条件(where != 条件)不能使用索引，可以优化为in 查询； Like 模糊查询左匹配不能使用索引, 只有右匹配能使用索引； 数据区分度不大的字段不宜使用索引，如：性别只有男，女，每次过滤掉的数据很少，不宜使用索引； 在属性上进行计算不能命中索引； 其他实践 See https://www.jianshu.com/p/906fd3ca8dc7 MySQL 遇到的死锁问题 如何避免死锁： 以固定的顺序访问表和行； 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小； 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率； 降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁； 为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。 数据库索引的原理 https://www.jianshu.com/p/4c2a2b0ef3e0 BTREE与HASH索引的区别, 为什么要用 BTREE索引 Hash 索引只能够用于使用 = 或者 &lt;=&gt; 运算符的相等比较(但是速度更快)。Hash 索引不能够用于诸如 &lt; 等用于查找一个范围值的比较运算符； B-tree 索引可以用于使用 =, &gt;, &gt;=, &lt;, &lt;= 或者 BETWEEN 运算符的列比较。如果 LIKE 的参数是一个没有以通配符起始的常量字符串的话也可以使用这种索引。 https://www.cnblogs.com/alphago-1/articles/6724207.html https://mp.weixin.qq.com/s/dhGAUs-S3RbBaOL2yxh1Iw 聚集索引与非聚集索引的区别 聚集索引：数据行的物理顺序与列值(一般是主键的那一列)的逻辑顺序相同，一个表中只能有一个聚集索引。Mysql中聚集索引就是主键索引，如果没有主键，系统会自动创建一个隐含列作为表的聚集索引。 非聚集索引：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以有多个非聚集索引。 See https://www.cnblogs.com/s-b-b/p/8334593.html limit 20000 加载很慢怎么解决 选择合适的数据存储方案 聊聊 MongoDB 使用场景 聊聊 ElasticSearch 使用场景 倒排索引 事务隔离级别 未提交读(Read uncommitted) 已提交读(Read committed [RC])：只能读取到已经提交的数据 可重复读(Repeatable read [RR])：在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别 可串行化(Serializable) 我们较常用的是RC和RR References https://notes.diguage.com/mysql/ 缓存使用 Redis 有哪些类型 Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合) 类型 简介 特性 场景 String(字符串) 二进制安全 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M — Hash(字典) 键值对集合,即编程语言中的Map类型 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) 存储、读取、修改用户属性 List(列表) 链表(双向链表) 增删快,提供了操作某一段元素的API 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列 Set(集合) 哈希表实现,元素不重复 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 Sorted Set(有序集合) 将Set中的元素增加一个权重参数score,元素按score有序排列 数据插入集合时,已经进行天然排序 1、排行榜 2、带权重的消息队列 Redis 内部结构 Redis 内存淘汰机制 volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru：从数据集中挑选最近最少使用的数据淘汰 allkeys-random：从数据集中任意选择数据淘汰 no-enviction：当内存达到限制的时候，不淘汰任何数据，不可写入任何数据集，所有引起申请内存的命令会报错 聊聊 Redis 使用场景 http://blog.720ui.com/2017/redis_core_use Redis 持久化机制 RDB： 这是Redis默认的持久化方式，按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件； AOF： Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 See http://blog.720ui.com/2016/redis_action_03_rdb_aof Redis 集群方案与实现 http://blog.720ui.com/2016/redis_action_04_cluster Redis 为什么是单线程的 缓存崩溃 缓存降级 使用缓存的合理性问题 http://blog.720ui.com/2016/redis_action_01_use_core 消息队列 消息队列的使用场景 消息的重发补偿解决思路 消息的堆积解决思路 自己如何实现消息队列 如何保证消息的有序性 Kafka为什么快 Kafka是如何实现几十万的高并发写入 框架篇Spring BeanFactory 和 ApplicationContext 有什么区别 Spring IOC 如何实现 说说 Spring AOP Spring AOP 实现原理 动态代理（cglib 与 JDK） Spring 事务实现方式 Spring 事务底层原理 Spring 其他产品（Srping Boot、Spring Cloud、Spring Secuirity、Spring Data、Spring AMQP 等） Netty 为什么选择 Netty 说说业务中，Netty 的使用场景 原生的 NIO 在 JDK 1.7 版本存在 epoll bug 什么是TCP 粘包/拆包 TCP粘包/拆包的解决办法 Netty 线程模型 说说 Netty 的零拷贝 Netty 内部执行流程 Netty 重连实现 微服务篇微服务 微服务有哪些框架 如何解决跨域 http://blog.720ui.com/2016/web_cross_domain/ 你怎么理解 RPC 框架 https://binchencoder.github.io/2019/07/21/RPC%E6%A1%86%E6%9E%B6/ 说说 RPC 的实现原理 说说 Dubbo 的实现原理 你怎么理解 RESTful 如何理解 RESTful API 的幂等性 http://blog.720ui.com/2016/restful_idempotent 如何保证接口的幂等性 说说 CAP 定理、 BASE 理论 怎么考虑数据一致性问题 说说最终一致性的实现方案 微服务如何进行数据库管理 http://blog.720ui.com/2017/msa_design/ 如何应对微服务的链式调用异常 http://blog.720ui.com/2017/msa_design/ 对于快速追踪与定位问题 http://blog.720ui.com/2017/msa_design/ 分布式 谈谈业务中使用分布式的场景 Session 分布式方案 分布式锁的场景 分布式锁的实现方案 分布式事务 集群与负载均衡的算法与实现 说说分库与分表设计 http://blog.720ui.com/2017/mysql_core_08_multi_db_table/ 分库与分表带来的分布式困境与应对之策 http://blog.720ui.com/2017/mysql_core_09_multi_db_table2/ 高级进阶算法排序算法See http://data.biancheng.net/sort/ 冒泡排序 桶排序 插入排序 JVM References JVM8中内存基本操作 JVM内存结构 JVM内存管理 JVM内存模型(JMM) JVM垃圾回收 JVM垃圾回收之世代垃圾收集过程 性能优化 性能指标有哪些 如何发现性能瓶颈 性能调优的常见手段 说说你在项目中如何进行性能调优 面试官拷问 平时碰到系统CPU飙高和频繁GC，你会怎么排查？ https://www.jianshu.com/p/cf3d157e245f References http://blog.720ui.com/2018/java_interview_final https://www.jianshu.com/p/76959115d486"},{"title":"排查CPU负载高","date":"2019-11-29T14:53:08.000Z","updated":"2019-12-02T02:10:12.029Z","comments":true,"path":"2019/11/29/排查CPU负载高/","permalink":"https://binchencoder.github.io/2019/11/29/排查CPU负载高/","excerpt":"","text":"一、Overview本篇文章针对的是排查Java程序出现高负载的情况，如果是其他语言写的程序，如：php、python、go，无非就是换个工具，排查的步骤是类似的 以下三类工具 从原生的top、jstack到功能强大的Arthas 和 一键式查找的show-busy-java-threads，它们都各有长处。在合适的环境选择合适的工具才是考察一个IT人员能力的时候。 1. 原生方法Linux 原生命令：top、printf JDK自带命令工具：jstack、jstat 1.1. 找到最耗CPU的进程1top -c 显示进程运行信息列表 按数字1，显示多核CPU信息 键入P(大写p)，进程按照CPU使用率排序 键入M(大写m)，进程按照内存使用率排序 1.2. 找到最耗CPU的线程1top -H -p [PID] 显示一个进程的线程运行信息列表 例：1top -Hp 17326 如下图所示，可以看到多个高耗CPU使用率的线程 1.3. 转换线程PID为十六进制1printf \"%x\\n\" [线程PID] 转换多个线程数字为十六进制，使用时前面加0x 例： 12345chenbindeMacBook-Pro:~ chenbin$ printf '%x\\n' 17378 17379 17412 1742643e243e344044412 1.4. 查看堆栈，定位线程1jstack [进程PID] | grep [线程转换后十六进制] -A10 使用jstack获取进程PID堆栈，利用grep定位线程id，打印后续10行信息 例： 1jstack 17376 | grep '0x43e2' -A10 看上图中的“GC task thread#0 (ParallelGC)”，代表垃圾回收线程，该线程会负责进行垃圾回收。为什么会有两个线程一直在进行垃圾回收，并且占用那么高的CPU使用率呢？ 1.5. 存储堆栈，批量查看可以先将jstack堆栈信息存储起来 1jstack [进程PID] &gt; [文件] 例： 1jstack 17376 &gt; yao.dump 存储17376进程的堆栈信息，再使用cat + grep查找看看后面几个高CPU线程的堆栈信息。 1cat -n yao.dump | grep -A10 '0x4404' 可以看到线程0x4404【线程17426】产生堆栈信息，直指方法whileTrue 1.6. GC查看我们看到CPU占用率最高的并不是0x4404，而是0x43e2、0x43e3。但是并没法看到其中是什么类与方法，只有一条GC信息。 是不是死循环导致了GC太频繁，导致CPU使用率居高不下呢？我们使用jstat看下jvm的GC信息看看。 1jstat -gcutil [进程PID] [毫秒] [打印次数] 例： 1jstat -gcutil 17376 2000 5 查看17376进程的GC信息，每2秒打印一次，共打印5次 可以看到Full GC的次数高达506次，Full GC的持续时间很长，平均每次Full GC耗时达到9秒（4766/506，即GCT/FGC）。 确实验证了我们之前的想法，再返回第4或第5步查看其他几个高CPU占用率线程，找到非GC信息的堆栈，查看具体的代码。 2. Arthas (阿里开源)这是阿里开源出来的一个针对Java的线上诊断工具，功能非常强大，支持Linux/Mac/Windows，采用命令行交互模式 具体可以看我之前的一篇写Arthas的文章 3. show-busy-java-threads这个工具是useful-scripts 工具集的其中一个工具，用于快速排查Java CPU性能问题(top us值过高)，能自动查出运行Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用 NOTE： 这个工具只能在Linux下使用 二、References https://alibaba.github.io/arthas/ https://github.com/alibaba/arthas https://binchencoder.github.io/2018/07/22/UsefulScripts-Java%E8%84%9A%E6%9C%AC/#show-busy-java-threads-sh"},{"title":"Arthas","date":"2019-11-29T12:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/11/29/Arthas/","permalink":"https://binchencoder.github.io/2019/11/29/Arthas/","excerpt":"","text":"ArthasArthas 是Alibaba开源的Java诊断工具，深受开发者喜爱。 当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ 下载下载arthas-boot.jar，然后用java -jar的方式启动： 123curl -O https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar 如果从github下载有问题，可以使用gitee镜像 curl -O https://arthas.gitee.io/arthas-boot.jar watch方法执行数据观测 让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写OGNL表达式进行对应变量的查看。 watch 的参数比较多，主要是因为它能在 4 个不同的场景观察对象 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 express 观察表达式 condition-express 条件表达式 [b] 在方法调用之前观察 [e] 在方法异常之后观察 [s] 在方法返回之后观察 [f] 在方法结束之后(正常返回和异常返回)观察 [E] 开启正则表达式匹配，默认为通配符匹配 [x:] 指定输出结果的属性遍历深度，默认为 1 Samples watch123watch com.xxx.uac.service.OrgService getCompanyStopedUserDeptNode \"&#123;params, returnObj&#125;\" params[0]==10 -b -s -x 5watch com.xxx.search.searchcenter.spi.sp.Searcher execute \"&#123;params, returnObj&#125;\" \"params[0].&#123;? #this.routings[0]==2&#125;.size()&gt;0\" -x 5 References https://alibaba.github.io/arthas/ https://github.com/alibaba/arthas"},{"title":"多线程, 到底该设置多少线程","date":"2019-11-09T10:35:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/11/09/多线程 到底该设置多少线程/","permalink":"https://binchencoder.github.io/2019/11/09/多线程 到底该设置多少线程/","excerpt":"","text":"一、前言作为2年以上的开发人员，如果还不理解多线程与多进程之间的区别，那你就赶紧停停手头的工作，回去好好复习吧 现在的程序设计中基本上都是多线程的，作为业务开发人员可能很多人都没有写过多线程的代码，因为这些高危的代码都由框架帮我们实现了，我们大多时间主要关注于实现自己的业务。但是如果搞懂多线程对于程序的调优和解决问题会很有帮助 在讲多线程之前，我先带领大家了解下其中的一些概念： 多线程：指的是这个程序（一个进程）运行时产生了不止一个线程 并行与并发： 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力 二、 线程执行线程的执行，是由CPU进行调度的，一个CPU在同一时刻只会执行一个线程 为了让用户感觉这些任务正在同时进行，操作系统利用了时间片轮转的方式，CPU给每个任务都服务一定的时间，然后把当前任务的状态保存下来，在加载下一任务的状态后，继续服务下一任务。任务的状态保存及再加载，这段过程就叫做上下文切换 三、为什么要用多线程系统执行流程 上图是我们我们在设计Web系统中一个比较简单的流程： 浏览器或者其他客户端发起网络请求 Web服务器解析请求 请求后端的数据库获取数据 数据库返回数据给应用服务，进行处理 将处理之后的数据返回给客户端（用户） 下面我们一起来看下以上的这几步流程会涉及到什么计算机处理呢 网络请求 —–&gt; 网络IO 解析请求 —–&gt; CPU 请求数据库 —–&gt; 网络IO MySQL查询数据 —–&gt; 磁盘IO MySQL返回数据 —–&gt; 网络IO 数据处理 —–&gt; CPU 返回数据给用户 —–&gt; 网络IO 在真实业务中我们不单单会涉及CPU计算，还有网络IO和磁盘IO处理，这些处理是非常耗时的。如果一个线程整个流程是上图的流程，真正涉及到CPU的只有2个节点，其他的节点都是IO处理，那么线程在做IO处理的时候，CPU就空闲出来了，CPU的利用率就不高 多线程提高程序执行效率 对于多核处理系统上，将要执行的任务分割成多个可并行执行线程，就可以提高执行速率 对于单处理器上多线程只能并发执行而不是并行，并发原理，其实就是CPU快速来回切换，在特定的时间执行特定的某一个任务。并发执行存在着线程间上下文切换的问题，会消耗一定的时间。如果不考虑阻塞，多线程并发执行其实比单线程执行更加耗费时间，线程过多也会造成CPU负荷过大，并且线程占用内存资源，创建销毁线程也都是需要开销的 多线程通过提供CPU利用率来提高效率。数据库访问、磁盘IO等操作的速度比CPU执行代码速度慢很多，单线程环境下，这些操作会阻塞程序执行，导致CPU空转，因此对于会产生这些阻塞的程序来说，使用多线程可以避免在等待期间CPU的空转，提高CPU利用率 四、提升QPS/TPS衡量系统性能如何，主要指标系统的（QPS/TPS） QPS/TPS：每秒能够处理请求/事务的数量 并发数：系统同时处理的请求/事务的数量 响应时间：就是平均处理一个请求/事务需要时长 QPS/TPS = 并发数/响应时间 上面公式代表并发数越大，QPS就越大；所以很多人就会以为调大线程池，并发数就会大，也会提升QPS 其实QPS还跟响应时间成反比，响应时间越大，QPS就会越小 虽然并发数调大了，就会提升QPS，但线程数也会影响响应时间，因为上面我们也提到了上下文切换的问题，那怎么设置线程数的呢？ 五、如何设置线程数最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目 备注这个公式也是前辈们分享的，当然之前看了淘宝前台系统优化实践的文章，和上面的公式很类似，不过在CPU数目那边，他们更细化了，上面的公式只是参考。不过不管什么公式，最终还是在生产环境中运行后，再优化调整 假如我们的服务器CPU核数为4核，一个任务线程cpu耗时为20ms，线程等待（网络IO、磁盘IO）耗时80ms，那最佳线程数目：( 80 + 20 )/20 * 4 = 20。也就是设置20个线程数最佳 从这个公式上面我们就得出，线程的等待时间越大，线程数就要设置越大，这个正好符合我们上面的分析，可提升CPU利用率。那从另一个角度上面说，线程数设置多大，是根据我们自身的业务的，需要自己去压力测试，设置一个合理的数值 设置线程数常规标准用上面的最佳公式，我们可能还不能评估出设置的线程数。因为很多业务集中到一个线程池中，不像上面的案例比较简单，事实上业务太多，怎么设置呢？这个就是要去压力测试去调整。不过我们的前辈已经帮我们总结了一个基础的值（最终还是要看运行情况自行调整） CPU密集型：操作内存处理的业务，一般线程数设置为：CPU核数 + 1 或者 CPU核数*2。核数为4的话，一般设置 5 或 8 IO密集型：文件操作，网络操作，数据库操作，一般线程设置为：cpu核数 / (1-0.9)，核数为4的话，一般设置 40 六、总结讲到这里大家是不是对线程有了更新的了解呢？遇到性能问题，应该要去分析为什么这么慢，系统的瓶颈出现在什么地方，减少瓶颈的耗时 另外推荐大家再去了解下线程的生命周期、Redis的线程模型 [线程生命周期] https://binchencoder.github.io/2018/08/31/Thread-State/ [为什么redis 是单线程的] https://cloud.tencent.com/developer/article/1120615"},{"title":"面试如戏, 全靠演技","date":"2019-11-04T10:35:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/11/04/面试如戏全靠演技/","permalink":"https://binchencoder.github.io/2019/11/04/面试如戏全靠演技/","excerpt":"","text":"面试http://www.ityouknow.com/cartoon/2019/10/25/twome.html"},{"title":"排查产线系统僵死","date":"2019-09-26T07:53:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/09/26/排查产线系统僵死/","permalink":"https://binchencoder.github.io/2019/09/26/排查产线系统僵死/","excerpt":"","text":"查看某个进程下各个线程运行情况 12345678910toptop - 15:14:57 up 18 days, 20:55, 2 users, load average: 8.29, 8.57, 8.88Tasks: 16 total, 1 running, 15 sleeping, 0 stopped, 0 zombieCpu(s): 15.8%us, 3.7%sy, 0.0%ni, 75.2%id, 4.7%wa, 0.0%hi, 0.7%si, 0.0%stMem: 197987944k total, 197041256k used, 946688k free, 1459640k buffersSwap: 8388604k total, 2936792k used, 5451812k free, 85205540k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 31318 root 20 0 18.3g 1.0g 22m S 4.0 0.5 423:46.06 java 1234567891011121314top -Hp 31318top - 15:15:43 up 18 days, 20:55, 2 users, load average: 7.89, 8.42, 8.81Tasks: 541 total, 0 running, 541 sleeping, 0 stopped, 0 zombieCpu(s): 15.8%us, 3.7%sy, 0.0%ni, 75.2%id, 4.7%wa, 0.0%hi, 0.7%si, 0.0%stMem: 197987944k total, 197030020k used, 957924k free, 1459640k buffersSwap: 8388604k total, 2936792k used, 5451812k free, 85206008k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 31470 root 20 0 18.3g 1.0g 22m S 3.9 0.5 213:51.56 java 31318 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:00.02 java 31324 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:17.63 java 31325 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:27.14 java 31326 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:27.71 java"},{"title":"下班后的生活改变人的一生","date":"2019-09-06T07:53:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/09/06/下班后的生活改变人的一生/","permalink":"https://binchencoder.github.io/2019/09/06/下班后的生活改变人的一生/","excerpt":"","text":""},{"title":"synchronized和lock","date":"2019-09-05T13:01:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/09/05/synchronized和lock/","permalink":"https://binchencoder.github.io/2019/09/05/synchronized和lock/","excerpt":"","text":"开篇Java 使用synchronized和Lock两种机制实现某种共享资源的同步 synchronized 使用Object对象本身的notify、wait、notifyAll调度机制 Lock 可以使用Condition(java.util.concurrent.locks.Condition)进行线程之间的调度，完成synchronized的所有功能 区别用法不一样在需要同步的对象中加入synchronized，synchronized既可以加在方法上，也可以加在特定的代码中，括号中表示需要锁的对象。而Lock需要显示的指定起始位置和终点位置。synchronized是托管给JVM执行的，而Lock的锁定是通过代码实现的，它有比synchronized 更精确的线程定义 性能不一样在JDK1.5中增加的ReentrantLock, 它不仅拥有和synchronized相同的并发性和内存语义，还增加了锁投票，定时锁。等候和中断锁等。 他们的性能在不同的情况下会不同：在资源竞争不是很激烈的情况下，synchronized的性能要优于ReentantLock, 而在资源竞争很激烈的情况下， synchronized的性能会下降的比较快，而ReentantLock的性能基本保持不变 锁机制不一样synchronized获得锁和释放锁的机制都在代码块中，当获得锁时，必须以相反的机制去释放，并且自动解锁，不会因为异常导致没有被释放而导致死锁。 Lock需要开发人员手动去释放，并且在finally代码块中，否则可能引起死锁问题。Lock提供了更强大的功能，可以通过tryLock的方式采用非阻塞的方式获取锁。"},{"title":"TCP三次握手和四次握手","date":"2019-08-31T09:36:21.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/31/TCP三次握手和四次握手/","permalink":"https://binchencoder.github.io/2019/08/31/TCP三次握手和四次握手/","excerpt":"","text":"唠叨几句笔者最近在进行跳槽的前期准备，把基础知识重新温故了一遍，整理了一篇Java面试圣经，估计很多人看到都会望而却步，停止跳槽的步伐 😅 这篇文章不仅适用于即将准备跳槽的Java程序猿朋友，也同样适用于希望扩充自己知识面的Java开发者。 在Java面试圣经，网络协议这一块属于进阶篇，属于基础偏上的内容。在本文中我们会深入学习下TCP协议 TCP协议说到TCP协议，大家应该能联想到TCP/IP，这是互联网世界中非常重要的一个名词。TCP/IP不是一个协议，而是一个协议族的统称。里面包括了IP协议、IMCP协议、TCP协议，以及我们更加熟悉的http、ftp、pop3协议等等。 本文我们主要介绍TCP协议，TCP 用于应用程序之间的通信。 当应用程序希望通过 TCP 与另一个应用程序通信时，它会发送一个通信请求。这个请求必须被送到一个确切的地址。在双方“握手”之后，TCP 将在两个应用程序之间建立一个全双工 (full-duplex) 的通信。 这个全双工的通信将占用两个计算机之间的通信线路，直到它被一方或双方关闭为止。 下面就来详细介绍TCP如何在计算机之间通信的。 TCP三次握手 TCP 三次握手就好比两个人在街上隔着50米看见了对方，但是因为雾霾等原因不能100%确认，所以要通过招手的方式相互确定对方是否认识自己。 上图包括两部分：建立链接、传输数据 第一次握手 客户端发送SYN包(seq=x)到服务器，并进入SYN_SEND状态，等待服务器确认 SYN：同步序列编号（Synchronize Sequence Numbers） 第二次握手 服务器收到SYN包，必须确认客户端的SYN（ACK=x+1），同时自己也发送一个SYN包(seq=y)，即SYN+ACK包，此时服务器进入SYN_RECV状态 第三次握手 客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功） 状态，完成三次握手 最后通过动画演示一下 传输数据过程1.超时重传 超时重传机制用来保证TCP传输的可靠性。每次发送数据包时，发送的数据报都有seq号，接收端收到数据后，会回复ack进行确认，表示某一seq 号数据已经收到。发送方在发送了某个seq包后，等待一段时间，如果没有收到对应的ack回复，就会认为报文丢失，会重传这个数据包。 2.快速重传 接受数据一方发现有数据包丢掉了。就会发送ack报文告诉发送端重传丢失的报文。如果发送端连续收到标号相同的ack包，则会触发客户端的快速重 传。比较超时重传和快速重传，可以发现超时重传是发送端在傻等超时，然后触发重传;而快速重传则是接收端主动告诉发送端数据没收到，然后触发发送端重传。 3.流量控制 这里主要说TCP滑动窗流量控制。TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己 还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 滑动窗可以是提高TCP传输效率的一种机制。 4.拥塞控制 滑动窗用来做流量控制。流量控制只关注发送端和接受端自身的状况，而没有考虑整个网络的通信情况。拥塞控制，则是基于整个网络来考虑的。考虑一下这 样的场景：某一时刻网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多 的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风 暴”，TCP这个协议就会拖垮整个网络。为此，TCP引入了拥塞控制策略。拥塞策略算法主要包括：慢启动，拥塞避免，拥塞发生，快速恢复。 TCP四次握手 第一次握手 客户端进程发起连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 第二次握手 服务器收到连接释放报文，发送确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务器进入CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用程序，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了。但是服务器若发送数据，客户端依然要接收。这个状态还要持续一段时间，也就是CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 第三次握手 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 第四次握手 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 最后通过动画演示一下 常见面试题为什么连接的时候是三次握手，关闭的时候是四次握手？因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 为什么不能用两次握手进行连接？3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。 现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发 送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分 组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。 如果已经建立了连接，但是客户端突然出现故障了怎么办？TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 End在我近期学习的过程中，我发现通过亲自画图的方式边学边理解，印象会更深刻。 故：接下来在我的文章中我都会尽可能挂上图片，提供给读者清俗易懂的文章，希望大家继续关注我的博客"},{"title":"Java面试之基础篇 - HashMap","date":"2019-08-29T13:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/29/Java面试之基础篇 - HashMap/","permalink":"https://binchencoder.github.io/2019/08/29/Java面试之基础篇 - HashMap/","excerpt":"","text":"前言掌握Java基础技能不仅能在工作中得心应手，在面试中也会占尽优势。相信大家在过去的面试过程中一定被问到过关于HashMap的知识，最近笔者也在准备面试，打算重新学习一遍Java集合的知识。在此带领大家一起来学习下 HashMap是Java程序员使用频率最高的映射(键值对)处理的数据类型。随着JDK(Java Development Kit)版本的升级，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。 Map接口类继承图 说明： HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 HashTable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 LinkedHashMap：是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 JDK1.8中HashMap是如何扩容的？与JDK1.7有什么区别先来看图，以下是JDK1.7中HashMap的扩容机制： 1.7中的扩容过程会出现hash冲突 在JDK1.8中HashMap的扩容有很大的改进，由于扩容数组的长度是2倍的关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化（左移一位就是 2 倍），在扩容中只用判断原来的 hash 值与左移动的一位（newtable 的值）按位与操作是 0 或 1 就行，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组 以下是JDK1.8源码核心实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K, V&gt;[] resize() &#123; Node&lt;K, V&gt;[] oldTab = table; //记住扩容前的数组长度和最大容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //超过数组在java中最大容量就无能为力了，冲突就只能冲突 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //长度和最大容量都扩容为原来的二倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) &#123; newThr = oldThr &lt;&lt; 1; &#125; double threshold &#125; //...... ...... //更新新的最大容量为扩容计算后的最大容量 threshold = newThr; //更新扩容后的新数组长度 Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; table = newTab; if (oldTab != null) &#123; //遍历老数组下标索引 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K, V&gt; e; //如果老数组对应索引上有元素则取出链表头元素放在e中 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果老数组j下标处只有一个元素则直接计算新数组中位置放置 if (e.next == null) &#123; newTab[e.hash &amp; (newCap - 1)] = e; &#125; else if (e instanceof TreeNode) //如果是树结构进行单独处理 &#123; ((TreeNode&lt;K, V&gt;) e).split(this, newTab, j, oldCap); &#125; else &#123; preserve order //能进来说明数组索引j位置上存在哈希冲突的链表结构 Node&lt;K, V&gt; loHead = null, loTail = null; Node&lt;K, V&gt; hiHead = null, hiTail = null; Node&lt;K, V&gt; next; //循环处理数组索引j位置上哈希冲突的链表中每个元素 do &#123; next = e.next; //判断key的hash值与老数组长度与操作后结果决定元素是放在原索引处还是新索引 if ((e.hash &amp; oldCap) == 0) &#123; //放在原索引处的建立新链表 if (loTail == null) &#123; loHead = e; &#125; else &#123; loTail.next = e; &#125; loTail = e; &#125; else &#123; //放在新索引（原索引 + oldCap）处的建立新链表 if (hiTail == null) &#123; hiHead = e; &#125; else &#123; hiTail.next = e; &#125; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; //放入原索引处 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; //放入新索引处 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 在 JDK1.7 中扩容操作时，哈希冲突的数组索引处的旧链表元素扩容到新数组时，如果扩容后索引位置在新数组的索引位置与原数组中索引位置相同，则链表元素会发生倒置（即如上面图1，原来链表头扩容后变为尾巴）；而在 JDK1.8 中不会出现链表倒置现象。 其次，由于 JDK1.7 中发生哈希冲突时仅仅采用了链表结构存储冲突元素，所以扩容时仅仅是重新计算其存储位置而已，而 JDK1.8 中为了性能在同一索引处发生哈希冲突到一定程度时链表结构会转换为红黑数结构存储冲突元素，故在扩容时如果当前索引中元素结构是红黑树且元素个数小于链表还原阈值（哈希冲突程度常量）时就会把树形结构缩小或直接还原为链表结构（其实现就是上面代码片段中的 split() 方法）。 HashMap是如何避免key碰撞See https://www.cnblogs.com/faunjoe88/p/7992234.html"},{"title":"Kafka是如何实现几十万的高并发写入","date":"2019-08-28T02:23:58.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/08/28/kafka是如何实现几十万的高并发写入/","permalink":"https://binchencoder.github.io/2019/08/28/kafka是如何实现几十万的高并发写入/","excerpt":"","text":"开篇在初识kafka 一文中讲了使用MQ(消息队列)来设计系统带来的好处：业务解耦、流量削峰、灵活扩展 当下流行的MQ有很多，因为我们公司在技术选型上选择了使用Kafka，所以我就整理了一篇关于Kafka的入门知识。通过技术选型 我们对业界主流的MQ进行了对比，Kakfa最大的优点就是吞吐量高 。 Kafka是高吞吐低延迟的高并发、高性能的消息中间件，在大数据领域有极为广泛的运用。配置良好的Kafka集群甚至可以做到每秒几十万、上百万的超高并发写入。 那么Kafka是如何做到这么高的吞吐量和性能的呢？在入门之后我们就来深入的扒一下Kafka的架构设计原理，掌握这些原理在互联网面试中会占据优势 持久化Kafka对消息的存储和缓存依赖于文件系统，每次接收数据都会往磁盘上写，人们对于“磁盘速度慢”的普遍印象，使得人们对于持久化的架构能够提供强有力的性能产生怀疑。 事实上，磁盘的速度比人们预期的要慢的多，也快得多，这取决于人们使用磁盘的方式。而且设计合理的磁盘结构通常可以和网络一样快。 通过上图对比，我们可以看出实际上顺序磁盘访问在某些情况下比随机内存访问还要快，其实Kafka就是利用这一优势来实现高性能写磁盘 See http://kafka.apachecn.org/documentation.html#persistence 页缓存技术 + 磁盘顺序写Kafka 为了保证磁盘写入性能，首先Kafka是基于操作系统的页缓存来实现文件写入的。 操作系统本身有一层缓存，叫做page cache，是在内存里的缓存，我们也可以称之为os cache，意思就是操作系统自己管理的缓存。 你在写磁盘文件的时候，可以直接写入os cache 中，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把os cache 里的数据真的刷入到磁盘中。 通过上图这种方式可以将磁盘文件的写性能提升很多，其实这种方式相当于写内存，不是在写磁盘 顺序写磁盘另外还有非常关键的一点，Kafka在写数据的时候是以磁盘顺序写的方式来落盘的，也就是说，仅仅将数据追加到文件的末尾(append)，而不是在文件的随机位置来修改数据。 对于普通的机械硬盘如果你要是随机写的话，确实性能极低，这里涉及到磁盘寻址的问题。但是如果只是追加文件末尾按照顺序的方式来写数据的话，那么这种磁盘顺序写的性能基本上可以跟写内存的性能本身是差不多的。 来总结一下： Kafka就是基于页缓存技术 + 磁盘顺序写 技术实现了写入数据的超高性能。 所以要保证每秒写入几万甚至几十万条数据的核心点，就是尽最大可能提升每条数据写入的性能，这样就可以在单位时间内写入更多的数据量，提升吞吐量。 零拷贝技术(zero-copy)说完了写入这块，再来谈谈消费这块。 大家应该都知道，从Kafka里我们经常要消费数据，那么消费的时候实际上就是要从kafka的磁盘文件里读取某条数据然后发送给下游的消费者，如下图所示： 如果Kafka以上面这种方式从磁盘中读取数据发送给下游的消费者，大概过程是： 先看看要读的数据在不在os cache中，如果不在的话就从磁盘文件里读取数据后放入os cache 接着从操作系统的os cache 里拷贝数据到应用程序进程的缓存里，再从应用程序进程的缓存里拷贝数据到操作系统层面的Socket缓存里，最后从Soket缓存里提取数据后发送到网卡，最后发送出去给下游消费者 整个过程如下图： 从上图可以看出，这整个过程有两次没必要的拷贝 一次是从操作系统的cache里拷贝到应用进程的缓存里，接着又从应用程序缓存里拷贝回操作系统的Socket缓存里。 而且为了进行这两次拷贝，中间还发生了好几次上下文切换，一会儿是应用程序在执行，一会儿上下文切换到操作系统来执行。 所以这种方式来读取数据是比较消耗性能的。 Kafka 为了解决这个问题，在读数据的时候是引入零拷贝技术。 也就是说，直接让操作系统的cache中的数据发送到网卡后传出给下游的消费者，中间跳过了两次拷贝数据的步骤，Socket缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到Socket缓存。 体会一下这个精妙的过程吧 通过零拷贝技术，就不需要把os cache里的数据拷贝到应用缓存，再从应用缓存拷贝到Socket缓存了，两次拷贝都省略了，所以叫做零拷贝。 对Socket缓存仅仅就是拷贝数据的描述符过去，然后数据就直接从os cache中发送到网卡上去了，这个过程大大的提升了数据消费时读取文件数据的性能。 而且大家会注意到，在从磁盘读数据的时候，会先看看os cache内存中是否有，如果有的话，其实读数据都是直接读内存的。 如果kafka集群经过良好的调优，大家会发现大量的数据都是直接写入os cache中，然后读数据的时候也是从os cache中读。 相当于是Kafka完全基于内存提供数据的写和读了，所以这个整体性能会极其的高。 总结通过学习Kafka的优秀设计，我们了解了Kafka底层的页缓存技术的使用，磁盘顺序写的思路，以及零拷贝技术的运用，才能使得Kafka有那么高的性能，做到每秒几十万的吞吐量。 名词解释 吞吐量(TPS)：吞吐量是指对网络、设备、端口、虚电路或其他设施，单位时间内成功地传送数据的数量（以比特、字节、分组等测量） References http://kafka.apachecn.org/documentation.html#maximizingefficiency http://kafka.apachecn.org/documentation.html#persistence"},{"title":"初识Kafka","date":"2019-08-27T12:53:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/08/27/初识kafka/","permalink":"https://binchencoder.github.io/2019/08/27/初识kafka/","excerpt":"","text":"开篇在微服务的架构设计中我们一般都会考虑服务之间互相调用的问题，如何做到更好的解耦设计。在秒杀的系统中会使用异步处理的方式来设计高并发、低延迟的系统架构。提到这些相信大家都会想到使用MQ(消息队列)来处理这些问题。 MQ(消息队列) 是跨进程通信方式之一，可理解为异步RPC，上游系统对调用结果的态度往往是重要不紧急。使用消息队列有几个好处：业务解耦、流量削峰、灵活扩展 技术选型现在业界主流的MQ有很多，比如：ActiveMQ、RabbitMQ、RocketMQ、Kafka 等，那么我们在技术选型中该怎么选择呢？ 特性 Kafka ActiveMQ RabbitMQ RocketMQ 单击吞吐量 10万级别，这是Kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算，日志采集等场景。 万级，吞吐量比RocketMQ和Kafka要低一个数量级 万级，吞吐量比RocketMQ和Kafka要低一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ topic数量对吞吐量的影响 topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，Kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多机器资源。 topic可以达到几百，几千个的级别，吞吐量会较小幅度的下降，这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic。 时效性 延迟在ms以内 ms级 微妙级，这是rabbitMq的一大特点，延迟是最低的 ms级 可用性 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 高，基于主从框架实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 消息可靠性 经过参数优化配置，消息可以做到0丢失 有较低的概率丢失数据 经过参数优化配置可以做到0丢失 功能支持 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 MQ领域的功能及其完备 基于erlang开发，所以并发能力很强，性能及其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 优劣势总结 kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集 非常成熟，功能强大，在业内大量的公司以及项目中都有应用。 偶尔会有较低概率的丢失消息。 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ维护越来越少，几个月才发布一个版本。 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用。 erlang语言开发，性能及其好，延时很低：吞吐量到万级，MQ功能比较完备，而且开源提供的管理界面非常棒，用起来很好用。社区相对比较活跃，几乎每个月都发布几个版本。在国内公司用 rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的 综上比较，可以看出RocketMQ和Kafka 优势较为明显，其实对于大多数的服务架构来说，吞吐量 和 消息可靠性 是我们选型中考虑较多的因素。接下来我们就一起来了解下Kafka 相关的内容 Kafka简介Apache Kafka 起源于LinkedIn，后来于2011年成为Apache开源项目。Kafka是用Scala和Java编写的。 Apache Kafka官网 上介绍，Kafka是一个分布式流处理平台，具有以下三个特性： 可以让你发布和订阅流式的记录。这一方面与消息队列或者企业消息系统类似； 可以储存流式的记录，并且有较好的容错性； 可以在流式记录产生时就进行处理。 接下来我们会就第一个特性，Kafka作为消息队列所具有的优势和特点： Kafka作为一个分布式消息队列，具有高性能、持久化、多副本备份、横向扩展能力。生产者往消息队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。 Kafka 架构总览 上图清晰的描述了Kafka的总体数据流，关于broker、topics、partitions 的一些元信息用zk来存 Producers 负责往Brokers 里面指定Topic中写消息 Consumers 从Brokers 中拉取指定Topics的消息，然后进行自己的业务处理 图中有3个topic： topic1有2个partition（topic1-partition1、topic1-partition2），两副本备份 topic2有3个parition（topic2-partition1、topic2-partition2、topic2-partition3），三副本备份 topic3有2个partition（topic3-partition1、topic3-partition2），两副本备份 Topic消息的主题、队列，每一个消息都有它的topic，Kafka通过topic对消息进行归类。Kafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以”topicName_partitionIndex”的命名方式命名，该dir包含了这个分区的所有消息(.log)和索引文件(.index)，这使得Kafka的吞吐率可以水平扩展 See http://kafka.apachecn.org/intro.html#intro_topics Partition每个分区都是一个 顺序的、不可变的消息队列， 并且可以持续的添加;分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 producer在发布消息的时候，可以为每条消息指定Key，这样消息被发送到broker时，会根据分区算法把消息存储到对应的分区中（一个分区存储多个消息），如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡。 See http://kafka.apachecn.org/intro.html#intro_distribution BrokerKafka server，用来存储消息，Kafka集群中的每一个服务器都是一个Broker，消费者将从Broker拉取订阅的消息 Producer向Kafka发送消息，生产者会根据topic分发消息。生产者也负责把消息关联到Topic上的哪一个分区。最简单的方式从分区列表中轮流选择。也可以根据某种算法依照权重选择分区。算法可由开发者定义。 See http://kafka.apachecn.org/intro.html#intro_producers CousumerConsumer实例可以是独立的进程，负责订阅和消费消息。消费者用consumerGroup来标识自己。同一个消费组可以并发地消费多个分区的消息，同一个partition也可以由多个consumerGroup并发消费，但是在consumerGroup中一个partition只能由一个consumer消费 See http://kafka.apachecn.org/intro.html#intro_consumers CousumerGroup同一个Consumer Group中的Consumers，Kafka将相应Topic中的每个消息只发送给其中一个Consumer 如图，这个 Kafka 集群有两台 server 的，四个分区(p0-p3)和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。 通常情况下，每个 topic 都会有一些消费组，一个消费组对应一个”逻辑订阅者”。一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个的进程。 在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些 partition 分区;如果一个实例消失，拥有的分区将被分发到剩余的实例。 Kafka 只保证分区内的记录是有序的，而不保证主题中不同分区的顺序。每个 partition 分区按照key值排序足以满足大多数应用程序的需求。但如果你需要总记录在所有记录的上面，可使用仅有一个分区的主题来实现，这意味着每个消费者组只有一个消费者进程。 Kafka配置项http://kafka.apachecn.org/documentation.html#configuration 名词解释 吞吐量(TPS)：吞吐量是指对网络、设备、端口、虚电路或其他设施，单位时间内成功地传送数据的数量（以比特、字节、分组等测量） References 消息中间件如何实现每秒几十万的高并发写入 kafka系统设计开篇 https://www.jianshu.com/p/d3e963ff8b70"},{"title":"深入理解JVM - 垃圾回收之世代垃圾收集过程","date":"2019-08-24T09:00:18.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/24/深入理解JVM - 垃圾回收之世代垃圾收集过程/","permalink":"https://binchencoder.github.io/2019/08/24/深入理解JVM - 垃圾回收之世代垃圾收集过程/","excerpt":"","text":"前言在 深入理解 - 垃圾回收 中我们详细讲解了JVM垃圾回收的机制、垃圾收集算法以及各种垃圾回收器的原理和优缺点。 通过上一篇文章我们知道现在主流的垃圾回收器都采用了分代收集算法，本文我们就来详细讲解下垃圾回收器是如何进行分代收集垃圾的 JVM分代分代其实就是将堆分成几个部分，分别是新生代、老年代和永久代 新对象会被分配在新生代内存。一旦新生代内存满了，就会开始对死掉的对象，进行所谓的小型垃圾回收过程。一旦新生代内存里，死掉的越多，回收过程就越快；至于那些还活着的对象，此时就会老化，并最终老到进入老年代内存。 Stop the World 事件 —— 小型垃圾回收属于一种叫 “Stop the World” 的事件。在这种事件发生时，所有的程序线程都要暂停，直到事件完成（比如这里就是完成了所有回收工作）为止。 老年代用来保存长时间存活的对象。通常设置一个阈值，当达到该年龄时，年轻代对象会被移动到老年代。最终老年代也会被回收。这个事件称为Major GC。 Major GC 也会触发STW（Stop the World）。通常，Major GC会慢很多，因为它涉及到所有存活对象。所以，对于响应性的应用程序，应该尽量避免Major GC。还要注意，Major GC的STW的时长受年老代垃圾回收器类型的影响。 永久代 包含JVM用于描述应用程序中类和方法的元数据。永久代是由JVM在运行时根据应用程序使用的类来填充的。此外，Java SE类库和方法也存储在这里。 如果JVM发现某些类不再需要，并且其他类可能需要空间，则这些类可能会被回收。 世代垃圾回收过程现在我们已经理解了为什么堆被分成不同的代，接下来我们一起来看看这些空间是如何相互作用，JVM中的对象是如何分配和老化的 首先，将任何新对象分配给Eden空间，两个survivor空间都是空的 当eden空间填满时，会触发轻微的垃圾收集 引用的对象被移动到第一个survivor空间，清除eden空间时，将删除未引用的对象 在下一次的Minor GC中，Eden区也会做同样的操作。删除未被引用的对象，并将被引用的对象移动到Survivor区。然后，他们被移动到了第二个Survivor区（S1）。此外，第一个Suvivor区（S0）中，在上一次Minor GC幸存的对象，会增加年龄，并被移动到S1中。待所有幸存对象都被移动到S1后，S0和Eden区会被清空。注意，Survivor区中有了不同年龄的对象。 在下一次的Minor GC中，会重复同样的动作。不过，这一次Survivor区会交换。被引用的对象移动到S0，幸存的对象增加年龄。Eden区和S1被清空 在较小的GC之后，当老化的物体达到一定的年龄阈值（在该示例中为8）时，它们从年轻一代晋升到老一代。 随着较小的GC持续发生，物体将继续被推广到老一代空间。 所以这几乎涵盖了年轻一代的整个过程。 最终，将主要对老一代进行GC，清理并最终压缩该空间。"},{"title":"深入理解JVM - 垃圾回收","date":"2019-08-23T15:00:18.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/23/深入理解JVM - 垃圾回收/","permalink":"https://binchencoder.github.io/2019/08/23/深入理解JVM - 垃圾回收/","excerpt":"","text":"前言在 JVM内存结构 中我们详细讲解了JVM中的内存是如何分布和组成的。 我们已经知道JVM内存结构主要有三大块：堆内存、方法区和栈内存，而堆又是JVM中占用内存最大的一块，但是堆占用的空间也不是无限的(在JVM中会有参数来进行控制)，在程序运行的过程中，会不断的产生对象，导致堆的内存空间减少，这时我们会想到一定有一种机制来进行回收。接下来我们就一起来看看JVM是如何回收不再使用的对象空间的。 垃圾回收机制Java垃圾回收主要关注堆 Java内存运行时区域中的程序计数器、虚拟机栈、本地方法栈 都是线程私有的，因此它们的生命周期与线程的生命周期是一样的；栈中的栈帧随着方法的进入和退出有条无紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器进行一些优化）。因此这几个区域的内存分配和回收都具备确定性，不需要过多考虑回收的问题，因此方法结束或者线程结束时，内存自然就随着回收了。 而Java堆不一样，一个接口中的多个实现类需要的内存不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存。 判断需要被回收对象的方法引用计数法 该方法简单高效，缺点是无法解决对象之间相互循环引用的问题 可达性分析法 解决了引用计数法 循环引用的问题 不可达的对象将暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程 垃圾收集算法一共有四种： 标记-清除算法、复制算法、标记-整理算法、分代收集算法 标记-清除算法(Mark-Sweep)这是最基础的算法，分为“标记” 和 “清除” 两个阶段。首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 缺点： 效率问题 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多会导致以后需要分配较大的对象空间时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作 复制算法(Copying) 现在的商业虚拟机都采用这种算法来回收新生代 复制算法是为了为了解决效率的问题，它将可用内存分为大小相等的两块。每次只使用其中的一块。当这一块的内存用完了，就将还活着的对象复制到另外一块上，然后把已使用的内存空间一次性清理掉。 这个算法的缺点是可用内存缩小为原来的一半 标记-整理算法(Mark-Compact)复制算法在对象存活率较高的情况下要进行较多的复制操作，效率会降低。 复制算法并不适用于老年代，所以才有了“标记-整理” 算法，标记的过程与“标记-清除” 是一样的，第二步不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端便捷以外的内存 分代收集算法 (Generational Collection)现代商业虚拟机的垃圾收集都采用这一算法，它是根据对象存活周期的不同将内存划分为几块并采用不同的垃圾收集算法。 一般将Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 新生代：每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制法，只需要付出少量存活对象的复制成本就可以完成收集 老年代：因为对象存活率高，没有额外空间对它进行分配担保，那就必须使用标记-清理 或者 标记-整理 算法来进行回收 垃圾回收器分类如果垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现 Serial收集器(串行收集器) 这是一个单线程的收集器，它在进行垃圾收集时，必须暂停掉其他所有的工作线程，直到它收集结束（Stop The World） Serial Old收集器 这是Serial收集器是老年代版本，也是一个单线程，使用 标记-整理 算法。 ParNew收集器(串行收集器) ParNew收集器是Serial收集器的多线程版本 除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数（例如：-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 Parallel Scavenge收集器(并行收集器)这是一个新生代收集器，使用复制算法，又是并行的多线程收集器。Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量(Througput) 吞吐量 = 运行用户代码时间 /（运行用户代码时间+垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% Parallel Old收集器(并行收集器) 这是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法 Sample: 12java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC MaxGCPauseMillis=100 -XX:MaxGCPauseMillis=100 CMS收集器(Concurrent Mark Sweep 并发标记扫描) 这是一种以获取最短回收停顿时间为目标的收集器 步骤： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 初始标记、重新标记这两个步骤仍然需要”Stop The World”。 优点： 并发收集，低停顿 缺点： 导致吞吐量降低：CMS收集器对CPU资源比较敏感，在并发阶段会占用一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量降低 无法处理浮动垃圾：可能出现”Concurrent Mode Failure”失败而导致另一次 Full GC（新生代和老年代同时回收） 的产生 产生空间碎片：空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC Sample: 12java -Xmx3550m -Xms3550m -Xmn2g -Xss128k-XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection G1收集器（Garbage-First）【重点】 G1 是一款面向服务端应用的垃圾收集器 步骤： 初始标记（Initial Marking） 并发标记（Concurrent Marking） 最终标记（Final Marking） 筛选回收（Live Data Counting and Evacuation） 优点： 并行与并发：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短 Stop-The-World 停顿的时间，部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行 分代收集：能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果 空间整合：G1从整体上看是基于“标记-整理”算法实现的，从局部（两个 Region 之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存碎片，收集后能提供规整的内存空间 可预测的停顿：可建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒 GC日志阅读 GC 日志是处理 Java 虚拟机内存问题的基础技能，它只是一些人为确定的规则，没有太多技术含量。 每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性，例如以下两段典型的 GC 日志： 1233.125:[GC[DefNew:3324K-＞152K（3712K），0.0025925 secs]3324K-＞152K（11904K），0.0031680 secs]100.667:[Full GC[Tenured:0 K-＞210K（10240K），0.0149142secs]4603K-＞210K（19456K），[Perm:2999K-＞2999K（21248K）]，0.0150007 secs][Times:user=0.01 sys=0.00，real=0.02 secs] 最前面的数字33.125： 和 100.667： 代表了 GC 发生的时间，这个数字的含义是从 Java 虚拟机启动以来经过的秒数。 GC 日志开头的 [GC 和 [Full GC 说明了这次垃圾收集的停顿类型，而不是用来区分新生代 GC 还是老年代 GC 的。 如果有 Full，说明这次 GC 是发生了 Stop-The-World 的，例如下面这段新生代收集器 ParNew 的日志也会出现 [Full GC（这一般是因为出现了分配担保失败之类的问题，所以才导致 STW）。如果是调用 System.gc() 方法所触发的收集，那么在这里将显示 [Full GC（System） 1[Full GC 283.736:[ParNew:261599K-＞261599K（261952K），0.0000288 secs] 接下来的 [DefNew、[Tenured、[Perm 表示 GC 发生的区域，这里显示的区域名称与使用的 GC 收集器是密切相关的，例如上面样例所使用的 Serial 收集器中的新生代名为 “Default New Generation”，所以显示的是 [DefNew。如果是 ParNew 收集器，新生代名称就会变为 [ParNew，意为 “Parallel New Generation”。如果采用 Parallel Scavenge 收集器，那它配套的新生代称为 PSYoungGen，老年代和永久代同理，名称也是由收集器决定的。 后面方括号内部的 3324K-＞152K（3712K）含义是GC 前该内存区域已使用容量 -＞ GC 后该内存区域已使用容量 （该内存区域总容量）。而在方括号之外的 3324K-＞152K（11904K） 表示 GC 前 Java 堆已使用容量 -＞ GC 后 Java 堆已使用容量 （Java 堆总容量） 再往后，0.0025925 secs 表示该内存区域 GC 所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如 [Times:user=0.01 sys=0.00，real=0.02 secs] ，这里面的 user、sys 和 real 与 Linux 的 time 命令所输出的时间含义一致，分别代表用户态消耗的 CPU 时间、内核态消耗的 CPU 事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time） CPU 时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘 I/O、等待线程阻塞，而 CPU 时间不包括这些耗时，但当系统有多 CPU 或者多核的话，多线程操作会叠加这些 CPU 时间，所以读者看到 user 或 sys 时间超过 real 时间是完全正常的 垃圾回收器的选择决定因素： 应用程序的场景 硬件的制约 吞吐量的需求 串行垃圾回收是最简单，但是效率最低的垃圾回收器。适用于控制台的单线程程序，简单任务。 并行垃圾回收器是64bit server默认的垃圾回收器，一般我们工作和产线上如果不配置，默认都是并行垃圾回收。对于一般的不要求吞吐的应用，并且硬件资源不是太充足的情况下，并行垃圾回收器差不多能满足需求。 重点 CMS垃圾回收器是对并行垃圾回收器的一个优化，它以CPU和系统资源为代价，换区GC的延迟。不会一GC就STW，而是根据情况STW。一定程度上是资源换取速度。 G1垃圾回收器是针对大Heap的垃圾回收器，如果heap分配的足够大，分的region的优先级回收策略会优先清理垃圾多的region。并且减少了内存空间碎片，分配大对象时不会因为无法找到连续的内存空间而提前触发下一次GC。 Option Description -XX:+UseSerialGC Serial Garbage Collector 串行垃圾回收器 -XX:+UseParallelGC Parallel Garbage Collector并行垃圾回收器 -XX:+UseConcMarkSweepGC CMS Garbage Collector并发标记垃圾回收器 -XX:ParallelCMSThreads= CMS Collector – number of threads to use 并发标记垃圾回收器使用的线程数，通常是cpu个数 -XX:+UseG1GC G1 Gargbage Collector 使用G1垃圾回收器 垃圾收集器参数总结 查看垃圾回收器12345chenbindeMacBook-Pro:BazelWorkspace chenbin$ java -XX:+PrintCommandLineFlags -version-XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGCjava version &quot;1.8.0_112&quot;Java(TM) SE Runtime Environment (build 1.8.0_112-b16)Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode) 名词术语 Full GC：新生代和老年代同时回收 References https://www.cnblogs.com/czwbig/p/11127159.html https://www.oschina.net/translate/java-gc"},{"title":"深入理解JVM - 内存结构","date":"2019-08-21T15:00:18.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/21/深入理解JVM - 内存结构/","permalink":"https://binchencoder.github.io/2019/08/21/深入理解JVM - 内存结构/","excerpt":"","text":"前言每个使用Java的开发者都知道Java字节码是在JRE中运行，JRE由Java API和JVM组成，JVM通过类加载器(Class Loader)加载Java应用，并通过Java API进行执行。 JVM则是JRE中的核心组成部分，承担分析和执行Java字节码的工作，而Java开发人员通常并不需要深入了解JVM运行情况就可以开发出大型应用和类库。尽管如此，相信所有的Java开发人员在工作中都会遇到这样的困惑：该为堆内存设置多大的空间？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域，遇到了该如何解决？ 在Java成长的道路上，对JVM调优是一项最基本的技能。如果你是一名资深的Java开发人员，一定会接到解决服务器性能的任务，而深入理解JVM则是解决这一问题的根本。 JVM内存结构 JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代 组成。而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配的; 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名 Non-Heap(非堆); 栈又分为虚拟机栈和本地方法栈，主要用于方法的执行。 上图详细标注了如何通过参数来控制各区域的内存大小 控制参数 -Xms 设置堆的最小空间大小 -Xmx 设置堆的最大空间大小 -XX:NewSize 设置新生代最小空间大小 -XX:MaxNewSize 设置新生代最大空间大小 -XX:PermSize 设置永久代最小空间大小 -XX:MaxPermSize 设置永久代最大空间大小 -Xss 设置每个线程的堆栈大小 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制 老年代空间大小 = 堆空间大小 - 年轻代大空间大小 Java运行时数据区Java虚拟机在执行Java程序的过程中会将其管理的内存划分为若干个不同的数据区域，这些区域有各自的用途、创建和销毁的时间，有些区域随虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束来建立和销毁。Java虚拟机所管理的内存包括以下几个运行时数据区域，如图： Java堆(Heap)对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区(Method Area)方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 程序计数器(Program Counter Register) 指向当前线程正在执行的字节码指令。是线程私有的 程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈(JVM Stack) 包括局部变量表、操作数栈、动态链接、返回地址 局部变量表：包含了方法执行过程中的所有变量。局部变量数组所需要的空间在编译期间完成分配，在方法运行期间不会改变局部变量数组的大小。 返回值：如果有返回值的话，压入调用者栈帧中的操作数栈中，并且把PC的值指向 方法调用指令 后面的一条指令地址。 操作数栈：操作变量的内存模型。操作数栈的最大深度在编译的时候已经确定（写入方法区code属性的max_stacks项中）。操作数栈的的元素可以是任意Java类型，包括long和double，32位数据占用栈空间为1，64位数据占用2。方法刚开始执行的时候，栈是空的，当方法执行过程中，各种字节码指令往栈中存取数据。 动态链接：每个栈帧都持有在运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接。 与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈(Native Method Stacks)本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。"},{"title":"认识Bazel","date":"2019-08-16T12:53:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/16/认识Bazel/","permalink":"https://binchencoder.github.io/2019/08/16/认识Bazel/","excerpt":"","text":"Bazel入门最近一直在研究网关这玩意，想借鉴我们公司的网关架构自己实现一下。思路是引入grpc-gateway，只是在这套系统的基础上增加一些定制的功能，如：负载均衡，权限验证，API参数检查。因为grpc-gateway采用的是Bazel来构建的，所以我要实现的网关也必须是用Bazel来构建。虽然在公司里接触过Bazel，但那也是在比较完善的平台上照葫芦画瓢。 为了完成自己的目标，只能硬着头皮边学边用，边用边学了 Bazel是什么Bazel 是一个开源的构建和测试工具，\b类似于Make、Maven及Gradle。它使用一种人易于理解的高级构建语言。Bazel 支持多种开发语言的项目，能够基于多个平台来构建。Bazel支持跨多个制品库和大规模用户的大型代码仓库。 为什么使用BazelBazel具有以下优势： 高级构建语言 Bazel使用一种抽象的、人易于理解的、语义级别的高级语言来描述项目的构建属性。与其他工具不同，Bazel基于库，二进制文件，脚本和数据集的概念进行操作，使您免于陷入将单个调用编写到编译器和链接器等工具的复杂性。 Bazel高效可靠 Bazel缓存以前完成的所有工作，并跟踪文件内容和构建命令的更改。通过这种方式，Bazel知道何时需要重建某些东西，并仅重建那些东西。为了进一步加快构建速度，您可以将项目设置为以并行和增量的方式构建。 Bazel是跨平台的 Bazel可以在Linux，macOS和Windows上运行。Bazel可以为同一个项目中的多个平台(包括桌面,服务器和移动设备)构建二进制文件和可部署软件包。 Bazel扩展性强 Bazel在使用100k+源文件处理构建时仍然保持良好的性能表现。它适用于多个制品存储库和10K用户规模。 核心概念Bazel根据在称为工作空间(WORKSPACE)的目录中组织的源代码构建软件。工作空间中的源文件以包的嵌套层次结构进行组织，其中每个包都是包含一组相关源文件和一个BUILD文件的目录。BUILD文件指定可以从源构建哪些软件输出。 工作空间工作空间是文件系统上的目录，每个工作空间目录都有一个名为WORKSPACE的文本文件，该文件可能为空(不建议这样做，至少定义一个name)，或者可能包含对构建输出所需的外部依赖项的引用。 Sample: 1workspace(name = &quot;com_github_binchencoder_ease_gateway&quot;) 程序包工作空间中代码组织的主要单元是包。包是相关文件的集合，以及它们之间的依赖关系的规范。每个程序包中包含一个BUILD文件，此文件中描述了此工具包的生成构建方式。 目标生成的目标，每个target又可以作为另外一个规则的输入。绝大部分的target属于两种基本类型中的一种，file和rule。另外，还有一种其他的target类型，package group。但是他们很少见。 进阶上述就是bazel最简单的描述，如果要学习bazel的详细进阶，可以访问起官网，官网上的文档非常详细，不过是英文的。 另外，我的github有几个更多的例子，可以进一步学习和理解bazel。 References: https://bazel.build https://github.com/grpc-ecosystem/grpc-gateway https://github.com/binchencoder/ease-gateway"},{"title":"JVM内存管理","date":"2019-08-11T12:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/11/JVM内存管理/","permalink":"https://binchencoder.github.io/2019/08/11/JVM内存管理/","excerpt":"","text":"JVM内存管理作为三大工业级别语言之一的JAVA如此受企业青睐有加，离不开她背后JVM的默默复出。只是由于JAVA过于成功以至于我们常常忘了JVM平台上还运行着像Clojure/Groovy/Kotlin/Scala/JRuby/Jython这样的语言。我们享受着JVM带来跨平台“一次编译到处执行”的便利和自动内存回收的安逸。 JVM是JAVA的核心基础，也是掌握JAVA语言的重难点，如果没有理解JVM的知识体系，就不要说自己是JAVA高手。最近我打算换工作，所以来重新回顾JVM的相关知识，为面试准备。JVM体系内知识点很多，通过以下关键词来简单概括下： 类结构，类加载器，加载，链接，初始化，双亲委派，热部署，隔离，堆，栈，方法区，计数器，内存回收，执行引擎，调优工具，JVMTI，JDWP，JDI，热替换，字节码，ASM，CGLIB，DCEVM 本文从JVM的内存结构入手，介绍JVM逻辑内存的分布和管理方式，同时列举常用的JVM调优工具和使用方法。 内存结构逻辑分区JVM内存从应用逻辑上可分为如下区域： 程序计数器程序计数器是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器，每个线程都需要一个程序计数器。在虚拟机的概念模型里（仅仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时，就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳准、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 简单理解就是程序计数器保证了程序的正常执行。 虚拟机栈方法执行时创建栈帧(存储局部变量，操作栈，动态链接，方法出口)编译时期就能确定占用空间大小，线程请求的栈深度超过jvm运行深度时抛StackOverflowError，当jvm栈无法申请到空闲内存时抛OutOfMemoryError，通过-Xss,-Xsx来配置初始内存 本地方法栈执行本地方法，如操作系统native接口 堆存放对象的空间，通过-Xmx,-Xms配置堆大小，当堆无法申请到内存时抛OutOfMemoryError 方法区存储类数据，常量，常量池，静态变量，通过MaxPermSize参数配置 对象访问初始化一个对象，其引用存放于栈帧，对象存放于堆内存，对象包含属性信息和该对象父类、接口等类型数据（该类型数据存储在方法区空间，对象拥有类型数据的地址） 内存模型堆内存堆内存是运行时的数据区，从中分配所有的Java类实例和数组的内存，可以理解为目标应用依赖的对象。堆在JVM启动时创建，并在应用程序运行时可能会增大或减小。可以使用-Xms`选项指定堆的大小。堆可以是固定大小或可变大小，具体取决于垃圾收集策略。可以使用-Xmx选项设置最大堆大小。默认情况下，最大堆大小设置为64M。 JVM堆内存在物理上分为两部分：新生代和老年代。新生代是为分配新对象而保留堆空间。当新生代占用完时，Minor GC垃圾收集器会对新生代区域执行垃圾回收动作。其中在新生代中生活了足够长的所有对象被迁移到老生代，从而释放新生代空间以进行更多的对象分配。此垃圾收集称为Minor GC。新生代分分为三个子区域：伊甸园Eden区和两个幸存区S0`和`S1。 关于新生代空间： 大多数新创建的对象都位于Eden区内存空间 当Eden区填满对象时，执行Minor GC并将所有幸存对象移动到其中一个幸存区空间 Minor GC还会检查幸存区对象并将其移动到其他幸存者空间，也即是幸存区总有一个是空的 在多次GC后还存活的对象被移动到老年代内存空间。至于经过多少次GC晋升老年代则由参数配置，通常为15 当老年区填满时，老年区同样会执行垃圾回收。老年区还包含那些经过多Minor GC后还存活的长寿对象。垃圾收集器在老年代内存中执行的垃圾回收称为Major GC，通常需要更长的时间。 Full GC ？？？ 非堆内存JVM堆以外的内存称为非堆内存。也即是JVM自身预留的内存区域，包含JVM缓存空间，类结构如常量池、字段和方法数据，方法，构造方法。类非堆内存的默认最大大小为64MB。可以用 -XX: MaxPermSize VM选项更改此选项，非堆内存通常包含如下性质的区域空间： 元空间（Metaspace） 在Java 8以上版本已经没有Perm Gen这块区域了，这也意味着不会再由关于“java.lang.OutOfMemoryError：PermGen”内存问题存在了。与驻留在Java堆中的Perm Gen不同，Metaspace不是堆的一部分。类元数据多数情况下都是从本地内存中分配的。默认情况下，元空间会自动增加其大小(直接又底层操作系统提供)，而Perm Gen始终具有固定的上限。可以使用两个新标志来设置Metaspace的大小，它们是：“ - XX：MetaspaceSize ”和“ -XX：MaxMetaspaceSize ”。Metaspace背后的含义是类的生命周期及其元数据与类加载器的生命周期相匹配。也就是说，只要类加载器处于活动状态，元数据就会在元数据空间中保持活动状态，并且无法释放。 代码缓存 运行Java程序时，它以分层方式执行代码。在第一层，它使用客户端编译器（C1编译器）来编译代码。分析数据用于服务器编译的第二层（C2编译器），以优化的方式编译该代码。默认情况下，Java 7中未启用分层编译，但在Java 8中启用了分层编译。实时（JIT）编译器将编译的代码存储在称为代码缓存的区域中。它是一个保存已编译代码的特殊堆。如果该区域的大小超过阈值，则该区域将被刷新，并且GC不会重新定位这些对象。Java 8中已经解决了一些性能问题和编译器未重新启用的问题，并且在Java 7中避免这些问题的解决方案之一是将代码缓存的大小增加到一个永远不会达到的程度。 方法区 方法区域是Perm Gen中空间的一部分，用于存储类结构（运行时常量和静态变量）以及方法和构造函数的代码。 内存池 内存池由JVM内存管理器创建，用于创建不可变对象池。内存池可以属于Heap或Perm Gen，具体取决于JVM内存管理器实现。 常量池 常量包含类运行时常量和静态方法，常量池是方法区域的一部分。 Java堆栈内存 Java堆栈内存用于执行线程。它们包含特定于方法的特定值，以及对从该方法引用的堆中其他对象的引用。 Java堆内存配置项 Java提供了许多内存配置项，我们可以使用它们来设置内存大小及其比例，常用的如下： VM Switch 描述 -Xms 用于在JVM启动时设置初始堆大小 -Xmx 用于设置最大堆大小 -Xmn 设置新生区的大小，剩下的空间用于老年区 -XX：PermGen 用于设置永久区存初始大小 -XX：MaxPermGen 用于设置Perm Gen的最大尺寸 -XX：SurvivorRatio 提供Eden区域的比例 -XX：NewRatio 用于提供老年代/新生代大小的比例，默认值为2 名词术语 Full GC：新生代和老年代同时回收 References: https://mp.weixin.qq.com/s/3_DEPdZTnGmdGBd5iTrVjQ https://www.cnblogs.com/manayi/p/9290490.html"},{"title":"Mac平台搭建Golang环境","date":"2019-08-08T04:10:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/08/Mac平台搭建Golang环境/","permalink":"https://binchencoder.github.io/2019/08/08/Mac平台搭建Golang环境/","excerpt":"","text":"Overview我大概是在两年前开始接触Golang语言，当时我们公司在北美成立研发中心，核心成员都是来自Google、微软等世界一流互联网公司。那时起我们才真正有了CTO这个职位。他来自Google，所以把Google的核心开发语言Golang带到我们公司并大力推广。要求全员学习Golang。 当时业务部门的同事都比较抵触学习Golang，包括我在内。大家都把Java语言当作了吃饭的饭碗，认为Golang是一门比较难的语言，不情愿在这个上面花时间。后来事实证明当初的想法是错误的，其实Golang入门还是很容易的，包括搭建环境，相比较Java而言，要容易的多。 听我啰嗦了这么多，大家可不要认为Golang就是万能的。任何一门语言都有其优点和缺点，Golang也不例外。 优点 Golang语法简单，可读性非常高，入门容易 基于 goroutines 和 channels 的简单并发编程 丰富的标准库 Golang性能优越 语言层面定义源代码的格式化 标准化的测试框架 Golang程序编译快，方便操作 Defer声明，避免忘记清理 方法多返回值：定义function可以返回多个值 缺点 Golang忽略了现代语言的进步 接口是结构类型 没有枚举 := / var 两难选择 说了这么多，让我们开始动手吧，本篇内容只会介绍如何搭建Golang开发环境 Mac搭建Golang开发环境介绍两种方式安装Golang环境 通过HomeBrew安装Homebrew有点类似于Linux操作系统中的apt-get（Ubuntu）、yum（yum），Mac的操作系统中使用它解决包依赖问题，套用官方的话来说：使用 Homebrew 安装 Apple 没有预装但 你需要的东西。 安装homebrew，已有则跳过1fabric:~ fabric$ ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装成功则提示 12345678910==&gt; Installation successful!==&gt; Homebrew has enabled anonymous aggregate user behaviour analytics.Read the analytics documentation (and how to opt-out) here: https://docs.brew.sh/Analytics.html==&gt; Next steps:- Run `brew help` to get started- Further documentation: https://docs.brew.sh 安装Golang 首先看看有哪些Golang版本可用 123456789101112131415chenbindeMacBook-Pro:BazelWorkspace chenbin$ brew search go==&gt; Formulaealgol68g gnu-go gocr google-authenticator-libpam gosu lgogdownloader percona-server-mongodbanycable-go go gocryptfs google-benchmark gotags libgosu protoc-gen-goarangodb go-bindata godep google-java-format goto mongo-c-driver pygobjectargon2 go-jira goenv google-sparsehash gource mongo-cxx-driver pygobject3aws-google-auth go-statik gofabric8 google-sql-tool govendor mongo-orchestration ringojsbogofilter go@1.10 goffice googler gowsdl mongodb spaceinvaders-gocargo-completion go@1.11 golang-migrate goolabs gox mongodb@3.0 spigotcertigo go@1.9 gollum goose gst-plugins-good mongodb@3.2 svgocgoban goaccess golo gopass gx-go mongodb@3.4 wegoclingo goad gom gor hugo mongodb@3.6 wireguard-godjango-completion gobby gomplate goreleaser jfrog-cli-go mongoose write-goodforego gobject-introspection goocanvas goreman jpegoptim pangofuego gobuster goofys gost lego pangomm 我们发现最新的有1.11可以使用 安装brew下最新版本的Golang 1fabric:~ fabric$ brew install go@1.11 配置Golang的环境变量 1chenbindeMacBook-Pro:BazelWorkspace chenbin$ vi /Users/chenbin/.bash_profile NOTE: 在Linux环境下是 vim ~/.bashrc 1234export GOROOT=/usr/local/goexport GOPATH=/Volumes/BazelWorkspace/bazel-goexport PATH=$GOROOT/bin:$GOPATH/bin:$PATH NOTE: GOPATH可以根据个人习惯设置为其他目录 让改动生效 1chenbindeMacBook-Pro:BazelWorkspace chenbin$ source ~/.bash_profile 试一试Golang是否安装成功 出现以下内容，则安装成功 123456789101112131415161718192021222324252627chenbindeMacBook-Pro:BazelWorkspace chenbin$ go envGOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOCACHE=&quot;/Users/chenbin/Library/Caches/go-build&quot;GOEXE=&quot;&quot;GOFLAGS=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;/Volumes/BazelWorkspace/bazel-go&quot;GOPROXY=&quot;&quot;GORACE=&quot;&quot;GOROOT=&quot;/usr/local/go&quot;GOTMPDIR=&quot;&quot;GOTOOLDIR=&quot;/usr/local/go/pkg/tool/darwin_amd64&quot;GCCGO=&quot;gccgo&quot;CC=&quot;clang&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot;GOMOD=&quot;&quot;CGO_CFLAGS=&quot;-g -O2&quot;CGO_CPPFLAGS=&quot;&quot;CGO_CXXFLAGS=&quot;-g -O2&quot;CGO_FFLAGS=&quot;-g -O2&quot;CGO_LDFLAGS=&quot;-g -O2&quot;PKG_CONFIG=&quot;pkg-config&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/hw/12mwhf310xd8m8k3bhtjxqp00000gn/T/go-build698784611=/tmp/go-build -gno-record-gcc-switches -fno-common&quot; 直接下载Golang包 直接在github下载源程序包 根据自己的需求下载适当的版本，推荐选择当下最新版本 下载地址： https://github.com/golang/go/releases 解压到你想配置的GOROOT目录 配置Golang环境变量（与通过Homebrew安装Golang的配置方式一样) END我个人推荐通过直接下载源程序包的方式安装，不仅省去了安装Homebrew的步骤，而且耗时更短。 我们开发golang的code一般放在 $GOPATH/src 目录下，下一章我会教大家如何利用工具简单而且方便的开发Golang NOTE: 提前剧透一下，大家可以先看看 https://github.com/linuxerwang/gobazel"},{"title":"Linux文件常用命令","date":"2019-08-02T09:36:21.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/02/Linux 文件常用命令/","permalink":"https://binchencoder.github.io/2019/08/02/Linux 文件常用命令/","excerpt":"","text":"Linux文件常用命令文件解压缩 解压 .tar.gz 和 .tgz1tar zxvf filename.tar.gz 压缩 .tar.gz 和 .tgz1tar zcvf filename.tar.gz linux下tar命令解压到指定的目录：1#tar xvf /bbs.tar.zip -C /zzz/bbs 把根目录下的bbs.tar.zip解压到/zzz/bbs下，前提要保证存在/zzz/bbs这个目录这个和cp命令有点不同，cp命令如果不存在这个目录就会自动创建这个目录！附：用tar命令打包例：将当前目录下的zzz文件打包到根目录下并命名为zzz.tar.gz 12&gt; #tar zcvf /zzz.tar.gz ./zzz&gt; 解压 .zip1unzip filename.zip 压缩 .zip12zip filename.zip压缩一个目录使用 -r 参数， -r 递归。 例： $ zip -r filename.zip dirname 解压 .rar1rar x filename.rar 压缩 .rar1rar a filename.rar dirname 文件搜索最强大的搜索命令：findfind命令是我们在Linux系统中用来进行文件搜索用的最多的命令，功能特别强大。但是我们要说的是尽量少用find命令去执行搜索任务，就算要搜索我们也应该尽量的缩小范围，也不要在服务器使用高峰期进行文件搜索，因为搜索也是很占系统资源的。这就需要我们在进行Linux文件整理的时候，尽量规范化，什么文件放在什么目录下都要有比较好的约定。 根据文件或目录名称搜索 find 【搜索目录】【-name或者-iname】【搜索字符】：-name和-iname的区别一个区分大小写，一个不区分大小写 1234find /etc -name init (精准搜索，名字必须为 init 才能搜索的到)find /etc -iname init (精准搜索，名字必须为 init或者有字母大写也能搜索的到)find /etc -name *init (模糊搜索，以 init 结尾的文件或目录名) find /etc -name init??? (模糊搜索，？ 表示单个字符，即搜索到 init___) 根据 文件大小 搜索比如：在根目录下查找大于 100M 的文件 1find / -size +204800 NOTE: 这里 +n 表示大于，-n 表示小于，n 表示等于1 数据块 == 512 字节 ==0.5KB，也就是1KB等于2数据块100MB == 102400KB==204800数据块 递归搜索并删除123find /tmp/98/upload -name *.avi -type f -print -exec rm -rf &#123;&#125; \\;find . -name abc -type d -print -exec rm -rf &#123;&#125; \\; “.” 表示从当前目录开始递归查找 “ -name ‘*.exe’ “根据名称来查找，要查找所有以.exe结尾的文件夹或者文件 “ -type f “查找的类型为文件 “-print” 输出查找的文件目录名 最主要的是是-exec了，-exec选项后边跟着一个所要执行的命令，表示将find出来的文件或目录执行该命令。exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{}，一个空格和一个\\，最后是一个分号"},{"title":"Spring Boot中application.properties与bootstrap.properties的区别","date":"2019-07-31T16:00:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/01/Spring Boot中application.properties与bootstrap.properties的区别/","permalink":"https://binchencoder.github.io/2019/08/01/Spring Boot中application.properties与bootstrap.properties的区别/","excerpt":"","text":"application.propertes (application.yml)现在使用SpringBoot是Java世界里的主流选择，它大大简化了应用初始搭建以及开发过程，该框架使用了特定的方式来进行配置，从而是开发人员不在需要定义样板化的配置。今天就带大家来了解下application.properties 使用application.properties，一般情况下主要用来配置服务中一些最基本的属性，如 数据库连接、日志相关配置。其他的用法还有 一般属性使用、自定义属性使用、属性间的引用(占位符)、随机数的使用、数据类型自动转换、嵌套属性注入 如：123456789101112spring.profiles.active=dev,vexillary-service,skylb,file_server,kafka_monitor_0.8,metrics#gRPCgrpc.port=6567#metricsmetrics.scrapePort=10000# logging levellogging.level.root=errorlogging.level.com.jingoal.grpc=debuglogging.level.com.jingoal.approval=debug application.properties与bootstrap.properties的区别两者主要区别是加载顺序不同，bootstrap.properties在application.properties 之前加载，bootstrap.properties用于应用程序上下文的引导阶段 典型场景 当时用Spring Cloud Config Server的时候，你应该在bootstraop.properties里面指定spring.application.name 和 spring.cloud.config.server.git.uri 一些加密/解密的信息 技术上, bootstrap.properties由父Spring ApplicationContext加载。父ApplicationContext 被加载到使用application.properties的之前。 当使用SpringCloud的时候，配置信息一般是从config server加载的，为了取得配置信息（比如密码等），你需要一些提早的或引导配置。因此，把config server信息放在bootstrap.properties，用来加载真正需要的配置信息。 属性覆盖问题启动上下文时，Spring Cloud会创建一个BootStrap Context，作为Spring应用的Application Context的父上下文。初始化的时候，Bootstrap Context负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment。 Bootstrap属性有高优先级，默认情况下，他们不会被本地配置覆盖。Bootstrap Context和Application Context有着不同的约定，所以新增了一个bootstrap.properties，而不是使用application.properties。保证Bootstrap Context和Application Context配置的分离。"},{"title":"MySQL优化原理","date":"2019-07-29T14:10:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/07/29/MySQL优化原理/","permalink":"https://binchencoder.github.io/2019/07/29/MySQL优化原理/","excerpt":"","text":"前言说起MySQL的查询优化，相信大家收藏了一堆奇技淫巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。 MySQL逻辑架构如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。 MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。 MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。 最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。 MySQL查询过程我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。 当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？ 客户端/服务端通信协议MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。 客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。 与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。 查询缓存在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。 MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。 既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外： 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗 基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如： 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存 最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。"},{"title":"Linux查看系统硬件信息","date":"2019-07-29T05:36:21.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/07/29/Linux查看系统硬件信息/","permalink":"https://binchencoder.github.io/2019/07/29/Linux查看系统硬件信息/","excerpt":"","text":"Linux查看系统硬件信息查看当前操作系统内核信息12chenbin@chenbin-ThinkPad:~$ uname -aLinux chenbin-ThinkPad 4.15.0-36-generic #39-Ubuntu SMP Mon Sep 24 16:19:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 查看当前操作系统发行版信息12chenbin@chenbin-ThinkPad:~$ cat /etc/issueUbuntu 18.04.1 LTS \\n \\l CPUCPU详细信息1234567891011121314151617181920212223242526ubuntu@mini-11:~$ lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bit #CPU 运行模式Byte Order: Little Endian #字节序CPU(s): 4 #CPU个数On-line CPU(s) list: 0-3 #在线 CPU 列表Thread(s) per core: 2 #每个核的线程数Core(s) per socket: 2 #每个cpu插槽核数/每颗物理cpu核数Socket(s): 1 #CPU插槽数NUMA node(s): 1 #NUMA 节点Vendor ID: GenuineIntel #厂商 IDCPU family: 6 #CPU系列Model: 69 #型号Model name: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHzStepping: 1CPU MHz: 2290.247 #CPU MHzCPU max MHz: 3300.0000 #CPU 最大 MHzCPU min MHz: 800.0000 #CPU 最小 MHzBogoMIPS: 5387.11Virtualization: VT-xL1d cache: 32K #一级缓存32K（google了下，这具体表示表示cpu的L1数据缓存为32k）L1i cache: 32K #一级缓存32K（具体为L1指令缓存为32K）L2 cache: 256K #二级缓存256KL3 cache: 4096K #三级缓存4096KNUMA node0 CPU(s): 0-3Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts NOTE: 查看12### 查看物理CPU个数 [root@DB-Server ~]# cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l [root@DB-Server ~]# dmesg | grep CPU | grep “Physical Processor ID” | uniq | wc -l12### 查看逻辑CPU个数 [root@DB-Server ~]# cat /proc/cpuinfo | grep “processor” | wc -l [root@DB-Server ~]# dmesg | grep “CPU” | grep “processor” | wc -l12### 查看CPU是几核的 [root@DB-Server ~]# cat /proc/cpuinfo | grep “cores” | uniq cpu cores : 312### 查看CPU的主频 [root@DB-Server ~]# cat /proc/cpuinfo | grep MHz | uniqcpu MHz : 800.000 [root@DB-Server ~]# cat /proc/cpuinfo | grep MHzcpu MHz : 800.000cpu MHz : 800.000cpu MHz : 800.00012### 查看CPU型号信息 [root@DB-Server ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 3 AMD Athlon(tm) II X3 450 Processor12### 通过physical id 可以判断物理CPU个数 [root@DB-Server ~]# cat /proc/cpuinfo | grep physical | uniq -cphysical id : 0address sizes : 48 bits physical, 48 bits virtualphysical id : 0address sizes : 48 bits physical, 48 bits virtualphysical id : 0address sizes : 48 bits physical, 48 bits virtual12### 查看CPU是否支持64位运算 [root@DB-Server ~]# cat /proc/cpuinfo | grep flags | grep ‘lm’ | wc -l3 结果大于0，说明支持64位运算，lm指long mode 支持lm则是64bit12345```[root@DB-Server ~]# getconf LONG_BITetl:/home/etl/$getconf LONG_BIT（另外一台服务器）说明当前CPU运行在32位模式下，当不代表CPU不支持64位 查看内存信息1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@DB-Server ~]# more /proc/meminfoMemTotal: 7541288 kBMemFree: 215388 kBBuffers: 186228 kBCached: 6433572 kBSwapCached: 77404 kBActive: 5489928 kBInactive: 1346252 kBActive(anon): 5193596 kBInactive(anon): 1015024 kBActive(file): 296332 kBInactive(file): 331228 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 9781240 kBSwapFree: 9430432 kBDirty: 0 kBWriteback: 0 kBAnonPages: 139432 kBMapped: 3878064 kBShmem: 5992240 kBSlab: 328284 kBSReclaimable: 159572 kBSUnreclaim: 168712 kBKernelStack: 2056 kBPageTables: 99256 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 13551884 kBCommitted_AS: 6943792 kBVmallocTotal: 34359738367 kBVmallocUsed: 301620 kBVmallocChunk: 34359431420 kBHardwareCorrupted: 0 kBAnonHugePages: 30720 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 8128 kBDirectMap2M: 2611200 kBDirectMap1G: 5242880 kB"},{"title":"RPC框架","date":"2019-07-21T10:00:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/07/21/RPC框架/","permalink":"https://binchencoder.github.io/2019/07/21/RPC框架/","excerpt":"","text":"前言大概是三年前我开始接触RPC，那时作为一个刚入职场三年的新兵，在公司技术架构决策层上还没有什么发言权。一直沿用前辈搭建的技术架构来开发应用系统，当时还没有前后端分离，采用的框架是Spring MVC + JSP，每个应用服务都是一个war，服务间的调用是通过共享访问数据库的代码包(jar)来实现，现在想想那时的技术是真的Low，导致现在欠了很多的技术债，直到现在我们也还在努力的还债。 后来随着服务不断增加，而且服务之前还需要互相调用，这种方式导致维护的成本越来越高。这时领导才下定决心要重构技术架构，要引入微服务并进行前后端分离，这才拉开了服务化的进程，从那时起我们开始引入RPC框架。 本片文章我会带领大家来了解这几个方面的内容：什么是RPC，为什么要使用RPC以及常见的RPC框架。 RPC简介RPC 是远程过程调用（Remote Procedure Call）的缩写形式，Birrell 和 Nelson 在 1984 发表于 ACM Transactions on Computer Systems 的论文《Implementing remote procedure calls》对 RPC 做了经典的诠释。RPC 是指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。而这一过程，对于开发人员来说是透明的。上图描述了数据报在一个简单的RPC传递的过程 当两个物理分离的子系统需要建立逻辑上的关联时，RPC 是牵线搭桥的常见技术手段之一。除 RPC 之外，常见的多系统数据交互方案还有分布式消息队列、HTTP 请求调用、数据库和分布式缓存等。 其中 RPC 和 HTTP 调用是没有经过中间件的，它们是端到端系统的直接数据交互。HTTP 调用其实也可以看成是一种特殊的 RPC，只不过传统意义上的 RPC 是指长连接数据交互，而 HTTP 一般是指即用即走的短链接。 RPC 在我们熟知的各种中间件中都有它的身影。Nginx/Redis/MySQL/Dubbo/Hadoop/Spark/Tensorflow 等重量级开源产品都是在 RPC 技术的基础上构建出来的，我们这里说的 RPC 指的是广义的 RPC，也就是分布式系统的通信技术。RPC 在技术中的地位好比我们身边的空气，它无处不在，但是又有很多人根本不知道它的存在。 为什么要使用RPC 首先要明确一点：RPC可以用HTTP协议实现，并且用HTTP是建立在TCP之上最广泛使用的RPC，但是互联网公司往往用自己的私有协议，比如鹅厂的JCE协议，私有协议不具备通用性为什么还要用呢？因为相比于HTTP协议，RPC采用二进制字节码传输，更加高效也更加安全。 现在业界提倡“微服务”的概念，而服务之间通信目前有两种方式，RPC就是其中一种。RPC可以保证不同服务之间的互相调用。即使是跨语言跨平台也不是问题，让构建分布式系统更加容易。 RPC框架都会有服务降级，流程控制的功能，保证服务的高可用。 RPC框架要想了解一个RPC框架是如何实现的，首先要明白以下几点： Call ID映射 我们怎么告诉远程机器我们要调用Multiply，而不是Add或者FooBar呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 序列化和反序列化 客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 网络传输 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西 常用的RPC框架常用的RPC框架在语言上支持Java的最多，golang次之 Netty - Netty框架不局限于RPC，更多的是作为一种网络协议的实现框架，比如HTTP，由于RPC需要高效的网络通信，就可能选择以Netty作为基础。 brpc是一个基于protobuf接口的RPC框架，在百度内部称为“baidu-rpc”，它囊括了百度内部所有RPC协议，并支持多种第三方协议，从目前的性能测试数据来看，brpc的性能领跑于其他同类RPC产品。 Dubbo是Alibaba开发的一个RPC框架，远程接口基于Java Interface, 依托于Spring框架。 gRPC的Java实现的底层网络库是基于Netty开发而来，其Go实现是基于net库。 Thrift是Apache的一个项目(http://thrift.apache.org)，前身是Facebook开发的一个RPC框架，采用thrift作为IDL (Interface description language)。 jsonrpc END后面我会继续发文深入介绍gRPC框架和在工作中是如何应用gRPC框架的"},{"title":"MySQL中 乐观锁、悲观锁、共享锁、排它锁、行锁、表锁的理解","date":"2019-01-20T02:00:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/01/20/MySQL锁的理解/","permalink":"https://binchencoder.github.io/2019/01/20/MySQL锁的理解/","excerpt":"","text":"前言MySQL/InnoDB的加锁，一直是一个面试中常见的话题。例如，数据库如果有高并发请求，如果保证数据完整性？产生死锁问题如何排查并解决？我在工作过程中，也会经常用到，乐观锁，排它锁 等。最近针对这几个概念进行学习，记录一下。 注: MySQL是一个支持插件式存储引擎的数据库系统。本文下面的所有介绍，都是基于InnoDB存储引擎，其他引擎的表现，会有较大的区别。 查看存储引擎MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL5.6.4，可以使用： 1SHOW ENGINES 乐观锁用数据版本(Version)记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库增加一个数字类型的“version”字段来实现。当读数据时，将version字段的值一同读出，数据每更新一次，对此version值加1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次读取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 举例 数据库表设计 三个字段，分别是id、value、version 1select id,value,version from TABLE where id=#&#123;id&#125; 每次更新表中的value字段时，为了防止发生冲突，需要这样操作 123update TABLEset value=2,version=version+1where id=#&#123;id&#125; and version=#&#123;version&#125;; 悲观锁与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中synchronized很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。 说到这里，由悲观锁涉及到的另外两个概念就出来了，他们就是共享锁与排它锁。共享锁和排它锁是悲观锁的不同实现，它俩都属于悲观锁的范畴。 使用排它锁举例： 要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作时，MySQL会立刻将结果进行提交。 我们可以使用命令设置MySQL为非autocommit模式： 1234567891011121314151617181920212223set autocommit=0;# 设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：# 1. 开始事务begin;/begin work;/start transaction; (三者选一就可以)# 2. 查询表信息select status from TABLE where id=1 for update;# 3. 插入一条数据insert into TABLE (id,value) values (2,2);# 4. 修改数据为update TABLE set value=2 where id=1;# 5. 提交事务commit;/commit work; 共享锁共享锁又称读锁 read lock，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。 如果事务T对数据A加上共享锁后，则其他事务只能对数据A再加共享锁，不能加排他锁。获得共享锁的事务只能读数据，不能修改数据 排他锁排他锁 exclusive lock（也叫writer lock）又称写锁。 排它锁是悲观锁的一种实现，在上面悲观锁也介绍过。 若事务 1 对数据对象A加上X锁，事务 1 可以读A也可以修改A，其他事务不能再对A加任何锁，直到事物 1 释放A上的锁。这保证了其他事务在事物 1 释放A上的锁之前不能再读取和修改A。排它锁会阻塞所有的排它锁和共享锁 读取为什么要加读锁呢：防止数据在被读取的时候被别的线程加上写锁， 使用方式：在需要执行的语句后面加上for update就可以了 行锁行锁又分共享锁和排他锁,由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。 NOTE: 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。 表锁如何加表锁 innodb 的行锁是在有索引的情况下,没有索引的表是锁定全表的. Innodb中的行锁与表锁 前面提到过，在Innodb引擎中既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候或只锁住一行呢？只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。 死锁死锁（Deadlock） 所谓死锁：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。 下列方法有助于最大限度地降低死锁： 按同一顺序访问对象。 避免事务中的用户交互。 保持事务简短并在一个批处理中。 使用低隔离级别。 使用绑定连接。"},{"title":"如何查看MariaDB bin log","date":"2018-09-04T13:53:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2018/09/04/查看MariaDB-binlog/","permalink":"https://binchencoder.github.io/2018/09/04/查看MariaDB-binlog/","excerpt":"","text":"MariaDB bin log今天在学习MariaDB在产线的部署架构时，重新了解了主从复制的原理，同时产生想查看bin log的好奇心，折腾了一番最终搞定 MariaDB主从复制 MySQL的复制就是基于二进制日志而完成的，其工作原理如下： 当MySQL的Master节点的数据有更改的时候，Master会主动通知Slave，让Slave主动来Master获取二进制日志，于是Slave开启一个I/O thread，向Master请求二进制日志中记录的语句；Master将二进制日志中记录的语句发给Slave，Slave则将这些语句存到中继日志中，进而从中继日志中读取一句，执行一句，直到所有的语句被执行完。而经SQL语句从中继日志中读取出来，再一一执行的进程叫做SQL thread；将这些语句执行完之后，从节点的数据就和主节点的数据相同了，这就是所谓的MySQL主从复制。 查看bin log在我们的一个测试环境上，通过如下命令查看 1234567891011121314151617181920212223242526272829MariaDB [(none)]&gt; show binary logs;1381 - You are not using binary loggingMariaDB [(none)]&gt; show variables like &apos;log_bin&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | OFF |+---------------+-------+错误原因：测试环境中部署的实例没有开启bin logMariaDB [(none)]&gt; set global log_bin_trust_function_creators=1;MariaDB [(none)]&gt; show variables like &apos;log_bin_trust_function_creators&apos;;+---------------------------------+-------+| Variable_name | Value |+---------------------------------+-------+| log_bin_trust_function_creators | ON |+---------------------------------+-------+这样添加了参数以后，如果mysqld重启，那个参数又会消失，因此记得在my.cnf配置文件中添加：log_bin_trust_function_creators=1log_bin=mysql_bin添加参数之后重启mysql 123456MariaDB [(none)]&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql_bin.000001 | 217795 |+------------------+-----------+ 123456789101112131415[root@mariadb bin]# mysqlbinlog –no-defaults mysql-bin.00001;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;mysqlbinlog: File &apos;&apos; not found (Errcode: 2)DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 遗留问题从上面Mariadb复制原理中我认为bin log记录的master上执行的sql语句，但是为什么bin log看不到呢？"},{"title":"使用正则引发的血案","date":"2018-09-01T13:43:21.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/09/01/使用正则引发的血案/","permalink":"https://binchencoder.github.io/2018/09/01/使用正则引发的血案/","excerpt":"","text":"正则表达式正则表达式, 一个十分古老而又强大的文本处理工具, 仅仅用一段非常简短的表达式语句, 便能够快速实现一个非常复杂的业务逻辑. 熟练地掌握正则表达式的话, 能够使你的开发效率得到极大的提升. 对于一些简单的表单式语句我们可以自己编写, 但是复杂一些并且通用的表达式我们往往会从网上直接拷贝来用. 经过大部分人实践过的一般不会出现问题, 但是偶尔也会踩坑. 最近我就在这个上面掉进了深坑. 案发最近产线上的一个服务连续两天出现问题, 现象就是访问出现 “502 Bad Gateway” 错误. 这个服务是部署在Tomcat下的, 字面上理解就是网关出现问题了, 第一次出现问题后为了紧急修复就直接重启了服务器, 重启后就正常了. 这次事故就这样草草收场，没有留下任何有用的日志信息用来分析, 就没有继续追查下去了. 偷懒是会受到惩罚的. 果不其然, 第二天问题继续出现, 并且还引起了其他的故障. 有了前车之鉴, 这一次受到了足够重视. 为了尽快恢复服务, 重启了部分节点用来恢复产线服务. 留了一个故障节点来断案. 断案排查思路 系统本身代码有问题, 如果是这样, 通过查看日志应该能发现集中的日志. 但是却没有, 初步排除代码逻辑处理错误 内部下游系统的问题导致的雪崩效应, 我们联系了内部下游系统观察了他们的监控，发现一起正常。可以排除下游系统故障对我们的影响 机器本身的问题, 查看机器监控, 排除机器故障问题。 即通过上述方法没有直接定位到问题。 解决方案之前为了快速恢复服务, 我们留下了一个故障节点, 从产线上摘除, 重启了其他节点恢复服务. 下面通过jstack来分析故障 查看当前Tomcat线程pid 12[root@xxx ~]# ps -ef | grep tomcatroot 142 1 0 Aug20 ? 02:46:26 /usr/local/jdk/jre/bin/java -Djava.util.logging.config.file=/usr/local/tomcat_xxx/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/tomcat_xxx/ -server -Xmx512m -Xms512m -XX:NewSize=64m -XX:MaxNewSize=128m -Djava.library.path=/usr/local/apr/lib -Dsun.lang.ClassLoader.allowArraySyntax=true -Djava.net.preferIPv4Stack=true -XX:PermSize=64M -XX:MaxPermSize=378m -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7080 -Dcom.sun.management.jmxremote -classpath /usr/local/tomcat_igoal/bin/bootstrap.jar -Dcatalina.base=/usr/local/tomcat_igoal -Dcatalina.home=/usr/local/tomcat_igoal -Djava.io.tmpdir=/usr/local/tomcat_igoal/temp org.apache.catalina.startup.Bootstrap start 打印jstack日志 1[root@xxx ~]# jstack -l 142 &gt; /tmp/jstack.txt jstack.txt 文件中的内容很多， 根据关键字(程序中的包名或者类名 等) 找到匹配的内容分析线程状态 如何分析线程状态，可以查看我博客中的一篇文章 Thread State 我通过查找 ‘xxx’ 关键字找到很多内容， 但是有些是正常的，就直接过滤掉。最后找到这样一段内容，发现jstack日志中大量重复出现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146&quot;http-192.168.0.185-12491-600&quot; #4971 daemon prio=5 os_prio=0 tid=0x00007f59a0334000 nid=0x1e7e runnable [0x00007f58c7ffc000] java.lang.Thread.State: RUNNABLE at java.util.regex.Pattern$5.isSatisfiedBy(Pattern.java:5251) at java.util.regex.Pattern$5.isSatisfiedBy(Pattern.java:5251) at java.util.regex.Pattern$CharProperty.match(Pattern.java:3776) at java.util.regex.Pattern$Curly.match(Pattern.java:4227) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.matchInit(Pattern.java:4804) at java.util.regex.Pattern$Prolog.match(Pattern.java:4741) at java.util.regex.Pattern$Begin.match(Pattern.java:3525) at java.util.regex.Matcher.match(Matcher.java:1270) at java.util.regex.Matcher.matches(Matcher.java:604) at com.xxx.xxx.util4sysmng.ValidateUtil.checkEmail(ValidateUtil.java:30) at com.xxx.xxx.register.action.RegisterController.regAccountSendVcode(RegisterController.java:538) at com.xxx.xxx.register.action.RegisterController$$FastClassByCGLIB$$58ed8719.invoke(&lt;generated&gt;) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191) at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:689) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:80) at com.xxx.prometheus.aspect.PrometheusAspect.process(PrometheusAspect.java:35) at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:65) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:161) at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:124) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:90) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:622) at com.xxx.xxx.register.action.RegisterController$$EnhancerByCGLIB$$972a02bd.regAccountSendVcode(&lt;generated&gt;) at sun.reflect.GeneratedMethodAccessor124.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:212) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:126) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:96) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:617) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:578) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:900) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:827) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778) at javax.servlet.http.HttpServlet.service(HttpServlet.java:617) at javax.servlet.http.HttpServlet.service(HttpServlet.java:723) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at com.xxx.xxx.sysmng.filter.SysmngSecurityFilter.doFilter(SysmngSecurityFilter.java:46) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:615) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:861) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:606) at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) at java.lang.Thread.run(Thread.java:745) 通过上面这段内容分析，在正则验证时出现大量线程等待，一直消耗系统CPU，最终造成服务处于假死状态，无法响应。 定位到具体的代码，经过测试 确认是验证Email的一个正则表达式有问题。代码中使用的Email正则表达式是这样写的：1^([a-z0-9A-Z]+[-|\\\\._]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\\\.)+[a-zA-Z]&#123;2,&#125;$ 测试代码123456789@Testpublic void testRegexFailed() &#123; String email = &quot;dnjnfslkffkjkjkslioeo9edkdjfks&quot;; String regex = &quot;^([a-z0-9A-Z]+[-|_|\\\\\\\\.]?)*[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\\\\\\\.)+[a-z0-9A-Z]&#123;2,&#125;$&quot;; Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(email); System.out.println(email + &quot; : &quot; + matcher.matches());&#125; 这段代码会出现死循环，使我电脑消耗CPU急剧增加，我在测试过程中打印了该进程消耗系统资源的数据1234567891011121314151617181920212223242526chenbin@chenbin-ThinkPad:~$ jps 23617 Launcher 21422 JUnitStarter chenbin@chenbin-ThinkPad:~$ top -Hp 21422Threads: 16 total, 1 running, 15 sleeping, 0 stopped, 0 zombie %Cpu(s): 30.8 us, 3.6 sy, 0.0 ni, 65.4 id, 0.1 wa, 0.0 hi, 0.1 si, 0.0 st KiB Mem : 7861372 total, 202784 free, 6652340 used, 1006248 buff/cache KiB Swap: 8076284 total, 3543620 free, 4532664 used. 872480 avail Mem PID USER PR NI VIRT RES SHR S% CPU% MEM TIME+ COMMAND 21425 chenbin 20 0 4468684 100360 18136 R 99.7 1.3 0:22.25 java 21422 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21434 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21435 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21436 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21437 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21438 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21439 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21440 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21441 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21442 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21443 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.88 java 21444 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.72 java 21445 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.09 java 21446 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21447 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 测试中发现 在输入的字符串比较短的时候，验证没有问题。但是在输入字符较长，并且不符合email规则的时候，会出现死循环。如果输入过长，但是符合这个email规则，也不会有这个问题！ 结案最后我们只能修改代码，替换这个正则表达式。因为这是通过的表达式，而且比较复杂，我们就没有造轮子。直接在网上找的, 经过验证，发现这个网站提供的正则比较靠谱Java Email Address Validation END能匹配空字符串的子匹配不要循环无限次。如果括号内的子表达式中的每一部分都可以匹配 0 次，而这个括号整体又可以匹配无限次，匹配过程中可能死循环。虽然现在有些正则表达式引擎已经通过办法避免了这种情况出现死循环了，比如 .NET 的正则表达式，但是我们仍然应该尽量避免出现这种情况。如果我们在写表达式时遇到了死循环，也可以从这一点入手。 正则表达式虽然使用起来很方便, 但是一定要慎用."},{"title":"Thread State","date":"2018-08-31T12:53:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/08/31/Thread-State/","permalink":"https://binchencoder.github.io/2018/08/31/Thread-State/","excerpt":"","text":"Java 线程状态分析Java线程的生命周期中, 存在着六种状态. 在Thread类里有一个枚举类型State, 定义了线程的几种状态. 下图比较清晰的展示了这六种状态之间的转换关系 NEW: 线程创建之后，但是还没有启动(not yet started)。这时候它的状态就是NEW RUNNABLE: 正在Java虚拟机下跑任务的线程的状态。在RUNNABLE状态下的线程可能会处于等待状态， 因为它正在等待一些系统资源的释放，比如IO BLOCKED: 阻塞状态，等待锁的释放，比如线程A进入了一个synchronized方法，线程B也想进入这个方法，但是这个方法的锁已经被线程A获取了，这个时候线程B就处于BLOCKED状态 WAITING: 等待状态，处于等待状态的线程是由于执行了3个方法中的任意方法。 Object的wait方法，并且没有使用timeout参数; Thread的join方法，没有使用timeout参数 LockSupport的park方法。 处于waiting状态的线程会等待另外一个线程处理特殊的行为。 再举个例子，如果一个线程调用了一个对象的wait方法，那么这个线程就会处于waiting状态直到另外一个线程调用这个对象的notify或者notifyAll方法后才会解除这个状态 TIMED_WAITING: 有等待时间的等待状态，比如调用了以下几个方法中的任意方法，并且指定了等待时间，线程就会处于这个状态。 Thread.sleep方法 Object的wait方法，带有时间 Thread.join方法，带有时间 LockSupport的parkNanos方法，带有时间 LockSupport的parkUntil方法，带有时间 TERMINATED: 线程中止的状态，这个线程已经完整地执行了它的任务 NEW StateNEW状态比较简单，实例化一个线程之后，并且这个线程没有开始执行，这个时候的状态就是NEW：12Thread thread = new Thread();System.out.println(thread.getState()); // NEW RUNNABLE State正在运行的状态123456789Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i = 0; i &lt; Integer.MAX_VALUE; i ++) &#123; System.out.println(i); &#125; &#125;&#125;, &quot;RUNNABLE-Thread&quot;);thread.start(); 使用jstack查看线程状态： 123456789101112131415161718192021&quot;RUNNABLE-Thread&quot; #10 prio=5 os_prio=31 tid=0x00007f8e04981000 nid=0x4f03 runnable [0x000070000124c000] java.lang.Thread.State: RUNNABLE at java.io.FileOutputStream.writeBytes(Native Method) at java.io.FileOutputStream.write(FileOutputStream.java:315) at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) - locked &lt;0x000000079764cc50&gt; (a java.io.BufferedOutputStream) at java.io.PrintStream.write(PrintStream.java:482) - locked &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221) at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:291) at sun.nio.cs.StreamEncoder.flushBuffer(StreamEncoder.java:104) - locked &lt;0x0000000797604d78&gt; (a java.io.OutputStreamWriter) at java.io.OutputStreamWriter.flushBuffer(OutputStreamWriter.java:185) at java.io.PrintStream.write(PrintStream.java:527) - eliminated &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at java.io.PrintStream.print(PrintStream.java:597) at java.io.PrintStream.println(PrintStream.java:736) - locked &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at study.thread.ThreadStateTest$1.run(ThreadStateTest.java:23) at java.lang.Thread.run(Thread.java:745) BLOCKED State线程A和线程B都需要持有lock对象的锁才能调用方法。如果线程A持有锁，那么线程B处于BLOCKED状态；如果线程B持有锁，那么线程A处于BLOCKED状态。例子中使用Thread.sleep方法主要是用于调试方便：1234567891011121314151617181920212223242526272829final Object lock = new Object();Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; invoke&quot;); try &#123; Thread.sleep(20000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;BLOCKED-Thread-A&quot;);Thread threadB = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; invoke&quot;); try &#123; Thread.sleep(20000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;BLOCKED-Thread-B&quot;);threadA.start();threadB.start(); 使用jstack查看线程状态。由于线程A先执行，线程B后执行，而且线程A执行后调用了Thread.sleep方法，所以线程A会处于TIMED_WAITING状态，线程B处于BLOCKED状态：123456789101112&quot;BLOCKED-Thread-B&quot; #11 prio=5 os_prio=31 tid=0x00007fa7db8ff000 nid=0x5103 waiting for monitor entry [0x000070000134f000] java.lang.Thread.State: BLOCKED (on object monitor) at study.thread.ThreadStateTest$3.run(ThreadStateTest.java:50) - waiting to lock &lt;0x0000000795a03bf8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)&quot;BLOCKED-Thread-A&quot; #10 prio=5 os_prio=31 tid=0x00007fa7db15a000 nid=0x4f03 waiting on condition [0x000070000124c000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$2.run(ThreadStateTest.java:39) - locked &lt;0x0000000795a03bf8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745) WAITING StateObject的wait方法、Thread的join方法以及Conditon的await方法都会产生WAITING状态。 1.没有时间参数的Object的wait方法1234567891011121314151617181920212223242526272829final Object lock = new Object();Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; lock.wait(); System.out.println(&quot;wait over&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;WAITING-Thread-A&quot;);Thread threadB = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.notifyAll(); &#125; &#125;&#125;, &quot;WAITING-Thread-B&quot;);threadA.start();threadB.start(); WAITING-Thread-A调用了lock的wait，处于WAITING状态：123456789101112131415&quot;WAITING-Thread-B&quot; #11 prio=5 os_prio=31 tid=0x00007f8de992d800 nid=0x5103 waiting on condition [0x000070000134f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$5.run(ThreadStateTest.java:84) - locked &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)&quot;WAITING-Thread-A&quot; #10 prio=5 os_prio=31 tid=0x00007f8dea193000 nid=0x4f03 in Object.wait() [0x000070000124c000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Object.wait(Object.java:502) at study.thread.ThreadStateTest$4.run(ThreadStateTest.java:71) - locked &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745) 2.Thread的join方法1234567891011121314151617Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread-A over&quot;); &#125;&#125;, &quot;WAITING-Thread-A&quot;);threadA.start();try &#123; threadA.join();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 主线程main处于WAITING状态：12345678910111213141516171819&quot;WAITING-Thread-A&quot; #10 prio=5 os_prio=31 tid=0x00007fd2d5100000 nid=0x4e03 waiting on condition [0x000070000124c000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$6.run(ThreadStateTest.java:103) at java.lang.Thread.run(Thread.java:745)&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fd2d3815000 nid=0x1003 in Object.wait() [0x0000700000182000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795a03ec0&gt; (a java.lang.Thread) at java.lang.Thread.join(Thread.java:1245) - locked &lt;0x0000000795a03ec0&gt; (a java.lang.Thread) at java.lang.Thread.join(Thread.java:1319) at study.thread.ThreadStateTest.WAITING_join(ThreadStateTest.java:118) at study.thread.ThreadStateTest.main(ThreadStateTest.java:13) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) 3.没有时间参数的Condition的await方法 Condition的await方法跟Obejct的wait方法原理是一样的，故也是WAITING状态 TIMED_WAITING StateTIMED_WAITING状态跟TIMEING状态类似，是一个有等待时间的等待状态，不会一直等待下去。 最简单的TIMED_WAITING状态例子就是Thread的sleep方法：123456789101112131415161718Thread threadA = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread-A over&quot;); &#125;&#125;, &quot;WAITING-Thread-A&quot;);threadA.start();try &#123; Thread.sleep(5000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(threadA.getState()); // TIMED_WAITING 或者是Object的wait方法带有时间参数、Thread的join方法带有时间参数也会让线程的状态处于TIMED_WAITING状态。 TERMINATED State线程终止的状态，线程执行完成，结束生命周期。12345678Thread threadA = new Thread();threadA.start();try &#123; Thread.sleep(5000l);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(threadA.getState()); // TERMINATED END了解线程的状态可以分析一些问题。 比如线程处于BLOCKED状态，这个时候可以分析一下是不是lock加锁的时候忘记释放了，或者释放的时机不对。导致另外的线程一直处于BLOCKED状态。 比如线程处于WAITING状态，这个时候可以分析一下notifyAll或者signalAll方法的调用时机是否不对。 java自带的jstack工具可以分析查看线程的状态、优先级、描述等具体信息。"},{"title":"UsefulScripts-Java脚本","date":"2018-07-22T05:46:57.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/07/22/UsefulScripts-Java脚本/","permalink":"https://binchencoder.github.io/2018/07/22/UsefulScripts-Java脚本/","excerpt":"show-busy-java-threads.sh 用法 示例 贡献者 show-duplicate-java-classes 用法 JDK开发场景使用说明 对于一般的工程 对于Web工程 Android开发场景使用说明 示例 贡献者 find-in-jars.sh 用法 示例 参考资料","text":"show-busy-java-threads.sh 用法 示例 贡献者 show-duplicate-java-classes 用法 JDK开发场景使用说明 对于一般的工程 对于Web工程 Android开发场景使用说明 示例 贡献者 find-in-jars.sh 用法 示例 参考资料 show-busy-java-threads.sh 用于快速排查Java的CPU性能问题(top us值过高)，自动查出运行的Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用。 PS，如何操作可以参见@bluedavy的《分布式Java应用》的【5.1.1 cpu消耗分析】一节，说得很详细： top命令找出有问题Java进程及线程id： 开启线程显示模式 按CPU使用率排序 记下Java进程id及其CPU高的线程id 用进程id作为参数，jstack有问题的Java进程 手动转换线程id成十六进制（可以用printf %x 1234） 查找十六进制的线程id（可以用grep） 查看对应的线程栈 查问题时，会要多次这样操作以确定问题，上面过程太繁琐太慢了。 用法12345678910111213show-busy-java-threads.sh# 从 所有的 Java进程中找出最消耗CPU的线程（缺省5个），打印出其线程栈。show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt;show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt; -p &lt;指定的Java Process&gt;############################### 注意：############################### 如果Java进程的用户 与 执行脚本的当前用户 不同，则jstack不了这个Java进程。# 为了能切换到Java进程的用户，需要加sudo来执行，即可以解决：sudo show-busy-java-threads.sh 示例1234567891011121314151617181920212223242526272829$ show-busy-java-threads.sh[1] Busy(57.0%) thread(23355/0x5b3b) stack of java process(23269) under user(admin):\"pool-1-thread-1\" prio=10 tid=0x000000005b5c5000 nid=0x5b3b runnable [0x000000004062c000] java.lang.Thread.State: RUNNABLE at java.text.DateFormat.format(DateFormat.java:316) at com.xxx.foo.services.common.DateFormatUtil.format(DateFormatUtil.java:41) at com.xxx.foo.shared.monitor.schedule.AppMonitorDataAvgScheduler.run(AppMonitorDataAvgScheduler.java:127) at com.xxx.foo.services.common.utils.AliTimer$2.run(AliTimer.java:128) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)[2] Busy(26.1%) thread(24018/0x5dd2) stack of java process(23269) under user(admin):\"pool-1-thread-2\" prio=10 tid=0x000000005a968800 nid=0x5dd2 runnable [0x00000000420e9000] java.lang.Thread.State: RUNNABLE at java.util.Arrays.copyOf(Arrays.java:2882) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:100) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:572) at java.lang.StringBuffer.append(StringBuffer.java:320) - locked &lt;0x00000007908d0030&gt; (a java.lang.StringBuffer) at java.text.SimpleDateFormat.format(SimpleDateFormat.java:890) at java.text.SimpleDateFormat.format(SimpleDateFormat.java:869) at java.text.DateFormat.format(DateFormat.java:316) at com.xxx.foo.services.common.DateFormatUtil.format(DateFormatUtil.java:41) at com.xxx.foo.shared.monitor.schedule.AppMonitorDataAvgScheduler.run(AppMonitorDataAvgScheduler.java:126) at com.xxx.foo.services.common.utils.AliTimer$2.run(AliTimer.java:128) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)... 上面的线程栈可以看出，CPU消耗最高的2个线程都在执行java.text.DateFormat.format，业务代码对应的方法是shared.monitor.schedule.AppMonitorDataAvgScheduler.run。可以基本确定： AppMonitorDataAvgScheduler.run调用DateFormat.format次数比较频繁。 DateFormat.format比较慢。（这个可以由DateFormat.format的实现确定。） 多个执行几次show-busy-java-threads.sh，如果上面情况高概率出现，则可以确定上面的判定。# 因为调用越少代码执行越快，则出现在线程栈的概率就越低。 分析shared.monitor.schedule.AppMonitorDataAvgScheduler.run实现逻辑和调用方式，以优化实现解决问题。 贡献者 silentforce改进此脚本，增加对环境变量JAVA_HOME的判断。 #15 liuyangc3 优化性能，通过read -a简化反复的awk操作 #51 发现并解决jstack非当前用户Java进程的问题 #50 show-duplicate-java-classes找出Java Lib（Java库，即Jar文件）或Class目录（类目录）中的重复类。 Java开发的一个麻烦的问题是Jar冲突（即多个版本的Jar），或者说重复类。会出NoSuchMethod等的问题，还不见得当时出问题。找出有重复类的Jar，可以防患未然。 用法 通过脚本参数指定Libs目录，查找目录下Jar文件，收集Jar文件中Class文件以分析重复类。可以指定多个Libs目录。 注意，只会查找这个目录下Jar文件，不会查找子目录下Jar文件。因为Libs目录一般不会用子目录再放Jar，这样也避免把去查找不期望Jar。 通过-c选项指定Class目录，直接收集这个目录下的Class文件以分析重复类。可以指定多个Class目录。 1234567891011# 查找当前目录下所有Jar中的重复类show-duplicate-java-classes# 查找多个指定目录下所有Jar中的重复类show-duplicate-java-classes path/to/lib_dir1 /path/to/lib_dir2# 查找多个指定Class目录下的重复类。 Class目录 通过 -c 选项指定show-duplicate-java-classes -c path/to/class_dir1 -c /path/to/class_dir2# 查找指定Class目录和指定目录下所有Jar中的重复类的Jarshow-duplicate-java-classes path/to/lib_dir1 /path/to/lib_dir2 -c path/to/class_dir1 -c path/to/class_dir2 JDK开发场景使用说明以Maven作为构建工程示意过程。 对于一般的工程123456# 在项目模块目录下执行，拷贝依赖Jar到目录target/dependency下$ mvn dependency:copy-dependencies -DincludeScope=runtime...# 检查重复类$ show-duplicate-java-classes target/dependency... 对于Web工程对于Web工程，即war maven模块，会打包生成war文件。 123456789# 在war模块目录下执行，生成war文件$ mvn install...# 解压war文件，war文件中包含了应用的依赖的Jar文件$ unzip target/*.war -d target/war...# 检查重复类$ show-duplicate-java-classes -c target/war/WEB-INF/classes target/war/WEB-INF/lib... Android开发场景使用说明Android开发，有重复类在编译打包时会报[Dex Loader] Unable to execute dex: Multiple dex files define Lorg/foo/xxx/Yyy。 但只会给出一个重复类名，如果重复类比较多时，上面打包/报错/排查会要进行多次，而Android的打包比较费时，这个过程比较麻烦，希望可以一次把所有重复类都列出来，一起排查掉。 以Gradle作为构建工程示意过程。 在App的build.gradle中添加拷贝库到目录build/dependencies下。 12345678910task copyDependencies(type: Copy) &#123; def dest = new File(buildDir, \"dependencies\") // clean dir dest.deleteDir() dest.mkdirs() // fill dir with dependencies from configurations.compile into dest&#125; 123456# 拷贝依赖$ ./gradlew app:copyDependencies...# 检查重复类$ show-duplicate-java-classes app/build/dependencies... 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ show-duplicate-java-classes WEB-INF/libCOOL! No duplicate classes found!================================================================================class paths to find:================================================================================1 : WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar2 : WEB-INF/lib/misc.htmlparser-0.0.0.jar3 : WEB-INF/lib/normandy.client-1.0.2.jar...$ show-duplicate-java-classes -c WEB-INF/classes WEB-INF/libFound duplicate classes in below class path:1 (293@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.orm-2.5.6.SEC02.jar2 (2@3): WEB-INF/lib/servlet-api-3.0-alpha-1.jar WEB-INF/lib/jsp-api-2.1-rev-1.jar WEB-INF/lib/jstl-api-1.2-rev-1.jar3 (104@2): WEB-INF/lib/commons-io-2.2.jar WEB-INF/lib/jakarta.commons.io-2.0.jar4 (6@3): WEB-INF/lib/jakarta.commons.logging-1.1.jar WEB-INF/lib/commons-logging-1.1.1.jar WEB-INF/lib/org.slf4j.jcl104-over-slf4j-1.5.6.jar5 (344@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar...================================================================================Duplicate classes detail info:================================================================================1 (293@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.orm-2.5.6.SEC02.jar 1 org/springframework/orm/toplink/TopLinkTemplate$13.class 2 org/springframework/orm/hibernate3/HibernateTemplate$24.class 3 org/springframework/orm/jpa/vendor/HibernateJpaDialect.class 4 org/springframework/orm/hibernate3/TypeDefinitionBean.class 5 org/springframework/orm/hibernate3/SessionHolder.class ...2 (2@3): WEB-INF/lib/servlet-api-3.0-alpha-1.jar WEB-INF/lib/jsp-api-2.1-rev-1.jar WEB-INF/lib/jstl-api-1.2-rev-1.jar 1 javax/servlet/ServletException.class 2 javax/servlet/ServletContext.class3 (104@2): WEB-INF/lib/commons-io-2.2.jar WEB-INF/lib/jakarta.commons.io-2.0.jar 1 org/apache/commons/io/input/ProxyReader.class 2 org/apache/commons/io/output/FileWriterWithEncoding.class 3 org/apache/commons/io/output/TaggedOutputStream.class 4 org/apache/commons/io/filefilter/NotFileFilter.class 5 org/apache/commons/io/filefilter/TrueFileFilter.class ......================================================================================class paths to find:================================================================================1 : WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar2 : WEB-INF/lib/misc.htmlparser-0.0.0.jar3 : WEB-INF/lib/normandy.client-1.0.2.jar4 : WEB-INF/lib/xml.xmlgraphics__batik-css-1.7.jar-1.7.jar5 : WEB-INF/lib/jakarta.ecs-1.4.2.jar... 贡献者tgic提供此脚本。友情贡献者的链接commandlinefu.cn|微博linux命令行精选 find-in-jars.sh在当前目录下所有jar文件里，查找类或资源文件。 用法1234find-in-jars.sh 'log4j\\.properties'find-in-jars.sh 'log4j\\.xml$' -d /path/to/find/directoryfind-in-jars.sh log4j\\\\.xmlfind-in-jars.sh 'log4j\\.properties|log4j\\.xml' 注意，后面Pattern是grep的 扩展正则表达式。 示例123$ ./find-in-jars 'Service.class$'./WEB-INF/libs/spring-2.5.6.SEC03.jar!org/springframework/stereotype/Service.class./rpc-benchmark-0.0.1-SNAPSHOT.jar!com/taobao/rpc/benchmark/service/HelloService.class 参考资料在多个Jar(Zip)文件查找Log4J配置文件的Shell命令行"},{"title":"gRPC Status and HTTP Code Relation","date":"2018-07-22T03:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2018/07/22/GRPC-Status-HTTP-Status/","permalink":"https://binchencoder.github.io/2018/07/22/GRPC-Status-HTTP-Status/","excerpt":"","text":"Status.INVALID_ARGUMENT [400] Status.OK [200] Status.CANCELLED [408] Status.UNKNOWN [500] Status.DEADLINE_EXCEEDED [408] Status.NOT_FOUND [404] Status.ALREADY_EXISTS [409] Status.PERMISSION_DENIED [403] Status.RESOURCE_EXHAUSTED [403] Status.FAILED_PRECONDITION [412] Status.ABORTED [409] Status.OUT_OF_RANGE [400] Status.UNIMPLEMENTED [501] Status.INTERNAL [500] Status.UNAVAILABLE [503] Status.DATA_LOSS [500] Status.UNAUTHENTICATED [401]"},{"title":"Hexo配合搭建github个人主页","date":"2018-07-21T10:03:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2018/07/21/Hexo搭建github主页/","permalink":"https://binchencoder.github.io/2018/07/21/Hexo搭建github主页/","excerpt":"前言“工欲善其事，必先利其器”，在搭建个人博客的过程中，我深刻体会到这句话的含义。虽然早就决定了要搭建个人博客，但是我并没有草草动手，而是提前做了大量的调研工作，包括采用哪种博客系统、选择哪种主题、怎么购买并绑定个性域名等等。事实证明，正因为前期的充分准备，搭建过程才能按部就班地进行。下面先介绍为何选择GitHub Pages和Hexo来搭建博客 准备 Node js环境 Git环境","text":"前言“工欲善其事，必先利其器”，在搭建个人博客的过程中，我深刻体会到这句话的含义。虽然早就决定了要搭建个人博客，但是我并没有草草动手，而是提前做了大量的调研工作，包括采用哪种博客系统、选择哪种主题、怎么购买并绑定个性域名等等。事实证明，正因为前期的充分准备，搭建过程才能按部就班地进行。下面先介绍为何选择GitHub Pages和Hexo来搭建博客 准备 Node js环境 Git环境 检查环境安装是否正确12345678chenbin@chenbin-ThinkPad:~$ node -vv8.9.4chenbin@chenbin-ThinkPad:~$ npm -v5.6.0chenbin@chenbin-ThinkPad:~$ git --versiongit version 2.17.1 如果结果如上, 则说明安装正确， 可以进行下一步了。 如果不正确， 则需要回头检查自己的安装过程 Install Hexo1$ npm install -g hexo-cli Link:https://hexo.io/zh-cn/docs/index.html 建站安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install NOTE: Init 必须是完全空的目录. 不能存在任何文件, 包括隐藏文件 新建完成后，指定文件夹的目录如下：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 查看建站效果自动根据当前目录下文件,生成静态网页1hexo g 运行本地服务, 出现以下结果说明本地服务运行成功. 这时就可以在浏览器输入http://localhost:4000/ 就可以看到效果了.12345hexo schenbin@chenbin-ThinkPad:~/.../github-workspace/Hexo-code$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 效果图: DeployHexo提供了快速方便的一键部署功能，让您只需一条命令就能将网站部署到服务器上。 1$ hexo deploy 在开始之前，您必须先在 _config.yml 中修改参数，一个正确的部署配置中至少要有 type 参数，例如：12deploy: type: git 您可同时使用多个 deployer，Hexo 会依照顺序执行每个 deployer。12345deploy:- type: git repo:- type: heroku repo: 缩进 YAML依靠缩进来确定元素间的从属关系。因此，请确保每个deployer的缩进长度相同，并且使用空格缩进。 详细说明请查看:https://hexo.io/zh-cn/docs/configuration.html Git Deploy以下是我在本地使用Git Deploy配置的例子:123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: https://github.com/binchencoder/binchencoder.github.io.git branch: master Install Git Deployer安装 hexo-deployer-git1$ npm install hexo-deployer-git --save 安装成功之后就可以使用Git将网站部署到指定的服务器上1234567891011chenbin@chenbin-ThinkPad:~/.../github-workspace/Hexo-code$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...位于分支 master无文件要提交，干净的工作区To https://github.com/binchencoder/binchencoder.github.io.git 8a8903c..dac6bed HEAD -&gt; master分支 &apos;master&apos; 设置为跟踪来自 &apos;https://github.com/binchencoder/binchencoder.github.io.git&apos; 的远程分支 &apos;master&apos;。INFO Deploy done: git 出现如上结果，就大功告成了。 Hexo Hello-World网站已经部署到Git服务上。就可以通过https://binchencode.github.io 地址访问部署的网站了"},{"title":"Hello World","date":"2018-07-21T07:00:18.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/07/21/hello-world/","permalink":"https://binchencoder.github.io/2018/07/21/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"}]}